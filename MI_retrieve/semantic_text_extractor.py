#!/usr/bin/env python3
"""
CLAMP3æ–‡æœ¬ç‰¹å¾æå–å™¨ - å®ç°æ–‡æœ¬åˆ°768ç»´ç‰¹å¾å‘é‡çš„è½¬æ¢
"""

import os
import sys
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModel, BertConfig
from typing import List, Union, Optional
import logging

# æ·»åŠ codeç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'code'))

from code.utils import CLaMP3Model
from code.config import *

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SemanticTextExtractor:
    """CLAMP3è¯­ä¹‰æ–‡æœ¬ç‰¹å¾æå–å™¨"""
    
    def __init__(self, model_path: str = None):
        """
        åˆå§‹åŒ–æ–‡æœ¬ç‰¹å¾æå–å™¨
        
        Args:
            model_path: CLAMP3æ¨¡å‹æƒé‡è·¯å¾„
        """
        if model_path is None:
            model_path = os.path.join(os.path.dirname(__file__), 'code', 
                                    'weights_clamp3_saas_h_size_768_t_model_FacebookAI_xlm-roberta-base_t_length_128_a_size_768_a_layers_12_a_length_128_s_size_768_s_layers_12_p_size_64_p_length_512.pth')
        
        self.model_path = model_path
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.tokenizer = None
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._initialize_model()
    
    def _initialize_model(self):
        """åˆå§‹åŒ–CLAMP3æ¨¡å‹å’Œtokenizer"""
        try:
            logger.info("ğŸ”„ åˆå§‹åŒ–CLAMP3æ¨¡å‹...")
            
            # åˆå§‹åŒ–tokenizer
            self.tokenizer = AutoTokenizer.from_pretrained(TEXT_MODEL_NAME)
            logger.info(f"âœ… åŠ è½½tokenizer: {TEXT_MODEL_NAME}")
            
            # åˆ›å»ºéŸ³é¢‘å’Œç¬¦å·é…ç½®
            audio_config = BertConfig(vocab_size=1,
                                    hidden_size=AUDIO_HIDDEN_SIZE,
                                    num_hidden_layers=AUDIO_NUM_LAYERS,
                                    num_attention_heads=AUDIO_HIDDEN_SIZE//64,
                                    intermediate_size=AUDIO_HIDDEN_SIZE*4,
                                    max_position_embeddings=MAX_AUDIO_LENGTH)
            
            symbolic_config = BertConfig(vocab_size=1,
                                       hidden_size=M3_HIDDEN_SIZE,
                                       num_hidden_layers=PATCH_NUM_LAYERS,
                                       num_attention_heads=M3_HIDDEN_SIZE//64,
                                       intermediate_size=M3_HIDDEN_SIZE*4,
                                       max_position_embeddings=PATCH_LENGTH)
            
            # åˆå§‹åŒ–CLAMP3æ¨¡å‹
            self.model = CLaMP3Model(
                audio_config=audio_config,
                symbolic_config=symbolic_config,
                text_model_name=TEXT_MODEL_NAME,
                hidden_size=CLAMP3_HIDDEN_SIZE,
                load_m3=CLAMP3_LOAD_M3
            )
            
            # åŠ è½½é¢„è®­ç»ƒæƒé‡
            if os.path.exists(self.model_path):
                try:
                    checkpoint = torch.load(self.model_path, map_location=self.device)
                    self.model.load_state_dict(checkpoint, strict=False)
                    logger.info(f"âœ… åŠ è½½æ¨¡å‹æƒé‡: {self.model_path}")
                except Exception as e:
                    logger.warning(f"âš ï¸  æƒé‡åŠ è½½å¤±è´¥: {e}")
                    logger.info("ğŸ’¡ ä½¿ç”¨é¢„è®­ç»ƒæ–‡æœ¬æ¨¡å‹ï¼Œå…¶ä»–éƒ¨åˆ†éšæœºåˆå§‹åŒ–")
            else:
                logger.warning(f"âš ï¸  æ¨¡å‹æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
                logger.info("ğŸ’¡ ä½¿ç”¨é¢„è®­ç»ƒæ–‡æœ¬æ¨¡å‹ï¼Œå…¶ä»–éƒ¨åˆ†éšæœºåˆå§‹åŒ–")
            
            # ç§»åŠ¨æ¨¡å‹åˆ°è®¾å¤‡
            self.model.to(self.device)
            self.model.eval()
            
            logger.info(f"âœ… CLAMP3æ¨¡å‹åˆå§‹åŒ–å®Œæˆ (è®¾å¤‡: {self.device})")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def extract_text_features(self, text: Union[str, List[str]], 
                            max_length: int = 128) -> np.ndarray:
        """
        æå–æ–‡æœ¬ç‰¹å¾å‘é‡
        
        Args:
            text: æ–‡æœ¬å­—ç¬¦ä¸²æˆ–æ–‡æœ¬åˆ—è¡¨
            max_length: æœ€å¤§æ–‡æœ¬é•¿åº¦
            
        Returns:
            å½¢çŠ¶ä¸º (batch_size, 768) çš„ç‰¹å¾å‘é‡
        """
        if self.model is None or self.tokenizer is None:
            raise RuntimeError("æ¨¡å‹æœªåˆå§‹åŒ–")
        
        # å¤„ç†è¾“å…¥
        if isinstance(text, str):
            text = [text]
        
        try:
            logger.info(f"ğŸ”„ æå–æ–‡æœ¬ç‰¹å¾ï¼Œè¾“å…¥æ•°é‡: {len(text)}")
            
            # æ–‡æœ¬tokenization
            encoded = self.tokenizer(
                text,
                max_length=max_length,
                padding=True,
                truncation=True,
                return_tensors='pt'
            )
            
            input_ids = encoded['input_ids'].to(self.device)
            attention_mask = encoded['attention_mask'].to(self.device)
            
            # æå–ç‰¹å¾
            with torch.no_grad():
                text_features = self.model.get_text_features(
                    input_ids, 
                    attention_mask, 
                    get_global=True
                )
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            features = text_features.cpu().numpy()
            
            logger.info(f"âœ… æ–‡æœ¬ç‰¹å¾æå–å®Œæˆï¼Œç‰¹å¾å½¢çŠ¶: {features.shape}")
            return features
            
        except Exception as e:
            logger.error(f"âŒ æ–‡æœ¬ç‰¹å¾æå–å¤±è´¥: {e}")
            raise
    
    def extract_single_text_feature(self, text: str) -> np.ndarray:
        """
        æå–å•ä¸ªæ–‡æœ¬çš„ç‰¹å¾å‘é‡
        
        Args:
            text: æ–‡æœ¬å­—ç¬¦ä¸²
            
        Returns:
            å½¢çŠ¶ä¸º (768,) çš„ç‰¹å¾å‘é‡
        """
        features = self.extract_text_features(text)
        return features[0]  # è¿”å›ç¬¬ä¸€ä¸ª(ä¹Ÿæ˜¯å”¯ä¸€ä¸€ä¸ª)ç‰¹å¾å‘é‡
    
    def compute_text_similarity(self, text1: str, text2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„è¯­ä¹‰ç›¸ä¼¼åº¦
        
        Args:
            text1: ç¬¬ä¸€ä¸ªæ–‡æœ¬
            text2: ç¬¬äºŒä¸ªæ–‡æœ¬
            
        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
        """
        features1 = self.extract_single_text_feature(text1)
        features2 = self.extract_single_text_feature(text2)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarity = np.dot(features1, features2) / (
            np.linalg.norm(features1) * np.linalg.norm(features2)
        )
        
        return float(similarity)
    
    def batch_extract_text_features(self, texts: List[str], 
                                  batch_size: int = 32) -> np.ndarray:
        """
        æ‰¹é‡æå–æ–‡æœ¬ç‰¹å¾
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
            
        Returns:
            å½¢çŠ¶ä¸º (len(texts), 768) çš„ç‰¹å¾çŸ©é˜µ
        """
        all_features = []
        
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i+batch_size]
            batch_features = self.extract_text_features(batch_texts)
            all_features.append(batch_features)
        
        return np.vstack(all_features)

def main():
    """æµ‹è¯•æ–‡æœ¬ç‰¹å¾æå–åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•CLAMP3æ–‡æœ¬ç‰¹å¾æå–...")
    
    # åˆå§‹åŒ–æå–å™¨
    extractor = SemanticTextExtractor()
    
    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        "tempo 90 BPM, å¤§è°ƒ, è½»æ¾æ„‰æ‚¦çš„éŸ³ä¹",
        "èŠ‚å¥ç¼“æ…¢, å°è°ƒ, é€‚åˆæ”¾æ¾å†¥æƒ³",
        "æ˜å¿«æ´»æ³¼, 120 BPM, é€‚åˆä¸“æ³¨å·¥ä½œ",
        "æ·±æ²‰å†…æ•›, 60 BPM, é€‚åˆæ·±åº¦æ€è€ƒ"
    ]
    
    # æå–ç‰¹å¾
    for text in test_texts:
        try:
            features = extractor.extract_single_text_feature(text)
            print(f"âœ… æ–‡æœ¬: {text}")
            print(f"   ç‰¹å¾å½¢çŠ¶: {features.shape}")
            print(f"   ç‰¹å¾èŒƒå›´: [{features.min():.4f}, {features.max():.4f}]")
            print()
        except Exception as e:
            print(f"âŒ æå–å¤±è´¥: {e}")
    
    # æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—
    print("ğŸ” æµ‹è¯•æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—...")
    similarity = extractor.compute_text_similarity(
        "tempo 90 BPM, å¤§è°ƒ, è½»æ¾æ„‰æ‚¦", 
        "èŠ‚å¥90, å¤§è°ƒ, æ”¾æ¾éŸ³ä¹"
    )
    print(f"âœ… ç›¸ä¼¼åº¦: {similarity:.4f}")

if __name__ == "__main__":
    main()