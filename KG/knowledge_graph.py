#!/usr/bin/env python3
"""
çŸ¥è¯†å›¾è°± (Knowledge Graph) - æƒ…ç»ªé©±åŠ¨éŸ³ä¹æ²»ç–—ç³»ç»Ÿæ ¸å¿ƒ

åŸºäºGEMSæ¨¡å‹å’ŒISOåŸåˆ™ï¼Œå®ç°27ç»´æƒ…ç»ªå‘é‡åˆ°éŸ³ä¹å‚æ•°çš„æ™ºèƒ½æ˜ å°„
"""

import numpy as np
import logging
from typing import Dict, List, Tuple, Any, Optional

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MusicRule:
    """éŸ³ä¹æ²»ç–—è§„åˆ™ç±»"""
    
    def __init__(self, name: str, conditions: Dict[str, float], 
                 parameters: Dict[str, Any], priority: str = "medium"):
        """
        åˆå§‹åŒ–éŸ³ä¹è§„åˆ™
        
        Args:
            name: è§„åˆ™åç§°
            conditions: æƒ…ç»ªæ¡ä»¶å­—å…¸ {"æƒ…ç»ªå": æœ€å°é˜ˆå€¼}
            parameters: éŸ³ä¹å‚æ•°å­—å…¸
            priority: è§„åˆ™ä¼˜å…ˆçº§ (critical/high/medium/low)
        """
        self.name = name
        self.conditions = conditions
        self.parameters = parameters
        self.priority = priority
        
        # ä¼˜å…ˆçº§æƒé‡
        self.priority_weights = {
            "critical": 4,
            "high": 3, 
            "medium": 2,
            "low": 1
        }
    
    def evaluate(self, emotion_dict: Dict[str, float]) -> Tuple[bool, float]:
        """
        è¯„ä¼°è§„åˆ™æ˜¯å¦åŒ¹é…å½“å‰æƒ…ç»ªçŠ¶æ€
        
        Args:
            emotion_dict: æƒ…ç»ªå­—å…¸ {"æƒ…ç»ªå": å¼ºåº¦å€¼}
            
        Returns:
            (æ˜¯å¦åŒ¹é…, åŒ¹é…å¼ºåº¦)
        """
        total_match_strength = 0.0
        matched_conditions = 0
        
        for emotion_name, threshold in self.conditions.items():
            if emotion_name in emotion_dict:
                emotion_value = emotion_dict[emotion_name]
                if emotion_value >= threshold:
                    # åŒ¹é…å¼ºåº¦ = è¶…å‡ºé˜ˆå€¼çš„ç¨‹åº¦
                    match_strength = emotion_value - threshold
                    total_match_strength += match_strength
                    matched_conditions += 1
                else:
                    # å¦‚æœæœ‰æ¡ä»¶ä¸æ»¡è¶³ï¼Œè§„åˆ™ä¸åŒ¹é…
                    return False, 0.0
        
        if matched_conditions == len(self.conditions):
            # æ‰€æœ‰æ¡ä»¶éƒ½æ»¡è¶³ï¼Œè®¡ç®—æ€»åŒ¹é…å¼ºåº¦
            avg_match_strength = total_match_strength / len(self.conditions)
            # åŠ ä¸Šä¼˜å…ˆçº§æƒé‡
            weighted_strength = avg_match_strength * self.priority_weights[self.priority]
            return True, weighted_strength
        
        return False, 0.0

class KnowledgeGraph:
    """
    æƒ…ç»ª-éŸ³ä¹çŸ¥è¯†å›¾è°±
    
    åŸºäºGEMS (Geneva Emotional Music Scale) æ¨¡å‹å®ç°
    27ç»´æƒ…ç»ªå‘é‡åˆ°éŸ³ä¹æ²»ç–—å‚æ•°çš„æ™ºèƒ½æ˜ å°„
    """
    
    def __init__(self):
        """åˆå§‹åŒ–çŸ¥è¯†å›¾è°±"""
        
        # 27ä¸ªæƒ…ç»ªåç§° (å›ºå®šé¡ºåºï¼Œå¯¹åº”27ç»´å‘é‡çš„ç´¢å¼•)
        self.emotion_names = [
            "é’¦ä½©", "å´‡æ‹œ", "å®¡ç¾æ¬£èµ", "å¨±ä¹", "æ„¤æ€’", "ç„¦è™‘", "æ•¬ç•", "å°´å°¬",
            "æ— èŠ", "å¹³é™", "å›°æƒ‘", "è”‘è§†", "æ¸´æœ›", "å¤±æœ›", "åŒæ¶", "åŒæƒ…",
            "å…¥è¿·", "å«‰å¦’", "å…´å¥‹", "ææƒ§", "å†…ç–š", "ææ€–", "å…´è¶£", "å¿«ä¹",
            "æ€€æ—§", "æµªæ¼«", "æ‚²ä¼¤"
        ]
        
        # é»˜è®¤/ä¸­æ€§éŸ³ä¹å‚æ•° (æ²»ç–—èµ·å§‹ç‚¹)
        self.default_music_parameters = {
            'tempo': 80.0,                    # BPMï¼Œä¸­ç­‰èŠ‚æ‹
            'mode': 0.5,                      # 0=å°è°ƒ, 1=å¤§è°ƒ, 0.5=ä¸­æ€§
            'dynamics': 0.5,                  # 0=å¾ˆè½», 1=å¾ˆå“, 0.5=é€‚ä¸­
            'harmony_consonance': 0.5,        # 0=ä¸åå’Œ, 1=åå’Œ, 0.5=ä¸­æ€§
            'timbre_preference': 'neutral_pad', # éŸ³è‰²åå¥½
            'pitch_register': 0.5,            # 0=ä½éŸ³, 1=é«˜éŸ³, 0.5=ä¸­éŸ³
            'density': 0.5,                   # 0=ç¨€ç–, 1=å¯†é›†, 0.5=é€‚ä¸­
            'emotional_envelope_direction': 'neutral'  # æƒ…ç»ªåŒ…ç»œæ–¹å‘
        }
        
        # å»ºç«‹åŸºäºGEMSæ¨¡å‹çš„è§„åˆ™ç³»ç»Ÿ
        self.rules = []
        self._initialize_gems_rules()
        
        logger.info("âœ… çŸ¥è¯†å›¾è°±åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   æƒ…ç»ªç»´åº¦: {len(self.emotion_names)}")
        logger.info(f"   è§„åˆ™æ•°é‡: {len(self.rules)}")
    
    def _initialize_gems_rules(self):
        """åˆå§‹åŒ–åŸºäºGEMSæ¨¡å‹çš„éŸ³ä¹æ²»ç–—è§„åˆ™"""
        
        # Criticalçº§åˆ«è§„åˆ™ (æç«¯æƒ…ç»ªçŠ¶æ€ï¼Œä¼˜å…ˆå¤„ç†)
        
        # 1. æåº¦ç„¦è™‘ â†’ ç¼“æ…¢ç¨³å®šéŸ³ä¹
        self.rules.append(MusicRule(
            name="æåº¦ç„¦è™‘ç¼“è§£",
            conditions={"ç„¦è™‘": 0.8},
            parameters={
                'tempo': 60.0,              # æ…¢èŠ‚æ‹é™ä½ç„¦è™‘
                'mode': 0.7,                # åå¤§è°ƒï¼Œæ¸©æš–æ„Ÿ
                'dynamics': 0.3,            # è½»æŸ”éŸ³é‡
                'harmony_consonance': 0.8,  # é«˜åå’Œåº¦ï¼Œå®‰å…¨æ„Ÿ
                'timbre_preference': 'warm_pad',
                'pitch_register': 0.3,      # ä½éŸ³åŸŸï¼Œç¨³å®šæ„Ÿ
                'density': 0.2,             # ç¨€ç–ï¼Œä¸å¢åŠ å‹åŠ›
                'emotional_envelope_direction': 'calming'
            },
            priority="critical"
        ))
        
        # 2. æåº¦æ„¤æ€’ â†’ æ¸è¿›å¼é‡Šæ”¾
        self.rules.append(MusicRule(
            name="æ„¤æ€’æƒ…ç»ªç–å¯¼",
            conditions={"æ„¤æ€’": 0.8},
            parameters={
                'tempo': 90.0,              # ä¸­ç­‰èŠ‚æ‹ï¼Œé¿å…æ¿€åŒ–
                'mode': 0.4,                # åå°è°ƒï¼Œç¬¦åˆæƒ…ç»ª
                'dynamics': 0.6,            # ä¸­ç­‰éŸ³é‡ï¼Œæœ‰è¡¨è¾¾ç©ºé—´
                'harmony_consonance': 0.3,  # é€‚åº¦ä¸åå’Œï¼Œæƒ…ç»ªé‡Šæ”¾
                'timbre_preference': 'expressive_strings',
                'pitch_register': 0.6,      # ä¸­é«˜éŸ³åŸŸ
                'density': 0.7,             # è¾ƒå¯†é›†ï¼Œæƒ…ç»ªå¯†åº¦
                'emotional_envelope_direction': 'descending'  # é€’å‡ï¼Œæƒ…ç»ªç¼“è§£
            },
            priority="critical"
        ))
        
        # 3. æåº¦ææƒ§ â†’ å®‰å…¨åŒ…å®¹
        self.rules.append(MusicRule(
            name="ææƒ§å®‰æŠš",
            conditions={"ææƒ§": 0.8},
            parameters={
                'tempo': 55.0,              # éå¸¸æ…¢ï¼Œå®‰å…¨æ„Ÿ
                'mode': 0.8,                # å¤§è°ƒï¼Œç§¯ææš—ç¤º
                'dynamics': 0.2,            # å¾ˆè½»ï¼Œéå¨èƒæ€§
                'harmony_consonance': 0.9,  # æåº¦åå’Œï¼Œå®‰å…¨æ„Ÿ
                'timbre_preference': 'soft_choir',
                'pitch_register': 0.4,      # åä½éŸ³ï¼ŒåŒ…å®¹æ„Ÿ
                'density': 0.1,             # æç¨€ç–ï¼Œä¸å¢åŠ åˆºæ¿€
                'emotional_envelope_direction': 'steady'
            },
            priority="critical"
        ))
        
        # Highçº§åˆ«è§„åˆ™ (æ˜¾è‘—æƒ…ç»ªçŠ¶æ€)
        
        # 4. é«˜åº¦å¹³é™ç»´æŒ
        self.rules.append(MusicRule(
            name="å¹³é™çŠ¶æ€ç»´æŒ",
            conditions={"å¹³é™": 0.7},
            parameters={
                'tempo': 65.0,
                'mode': 0.6,
                'dynamics': 0.4,
                'harmony_consonance': 0.7,
                'timbre_preference': 'nature_sounds',
                'pitch_register': 0.4,
                'density': 0.3,
                'emotional_envelope_direction': 'steady'
            },
            priority="high"
        ))
        
        # 5. é«˜åº¦æ‚²ä¼¤ â†’ æƒ…æ„Ÿæ”¯æŒ
        self.rules.append(MusicRule(
            name="æ‚²ä¼¤æƒ…æ„Ÿæ”¯æŒ",
            conditions={"æ‚²ä¼¤": 0.7},
            parameters={
                'tempo': 70.0,
                'mode': 0.3,                # å°è°ƒï¼Œæƒ…æ„Ÿå…±é¸£
                'dynamics': 0.4,
                'harmony_consonance': 0.6,
                'timbre_preference': 'gentle_piano',
                'pitch_register': 0.3,
                'density': 0.4,
                'emotional_envelope_direction': 'gentle_rise'  # è½»ç¼“ä¸Šå‡ï¼Œå¸Œæœ›æ„Ÿ
            },
            priority="high"
        ))
        
        # 6. é«˜åº¦å¿«ä¹ â†’ èƒ½é‡ç»´æŒ
        self.rules.append(MusicRule(
            name="å¿«ä¹èƒ½é‡ç»´æŒ",
            conditions={"å¿«ä¹": 0.7},
            parameters={
                'tempo': 100.0,
                'mode': 0.8,                # æ˜äº®å¤§è°ƒ
                'dynamics': 0.7,
                'harmony_consonance': 0.8,
                'timbre_preference': 'bright_ensemble',
                'pitch_register': 0.7,      # é«˜éŸ³åŸŸï¼Œæ˜äº®æ„Ÿ
                'density': 0.6,
                'emotional_envelope_direction': 'uplifting'
            },
            priority="high"
        ))
        
        # Mediumçº§åˆ«è§„åˆ™ (ä¸­ç­‰æƒ…ç»ªçŠ¶æ€)
        
        # 7. ä¸­åº¦ç„¦è™‘ â†’ æ¸è¿›æ”¾æ¾
        self.rules.append(MusicRule(
            name="ä¸­åº¦ç„¦è™‘ç¼“è§£",
            conditions={"ç„¦è™‘": 0.5},
            parameters={
                'tempo': 75.0,
                'mode': 0.6,
                'dynamics': 0.4,
                'harmony_consonance': 0.7,
                'timbre_preference': 'ambient_pad',
                'pitch_register': 0.4,
                'density': 0.3,
                'emotional_envelope_direction': 'calming'
            },
            priority="medium"
        ))
        
        # 8. å…´å¥‹+å¿«ä¹ç»„åˆ â†’ ç§¯æèƒ½é‡
        self.rules.append(MusicRule(
            name="ç§¯æå…´å¥‹çŠ¶æ€",
            conditions={"å…´å¥‹": 0.6, "å¿«ä¹": 0.5},
            parameters={
                'tempo': 110.0,
                'mode': 0.8,
                'dynamics': 0.7,
                'harmony_consonance': 0.7,
                'timbre_preference': 'energetic_mix',
                'pitch_register': 0.7,
                'density': 0.7,
                'emotional_envelope_direction': 'energizing'
            },
            priority="medium"
        ))
        
        # 9. æ€€æ—§æƒ…æ„Ÿ â†’ æ¸©æš–å›å¿†
        self.rules.append(MusicRule(
            name="æ€€æ—§æƒ…æ„ŸæŠšæ…°",
            conditions={"æ€€æ—§": 0.6},
            parameters={
                'tempo': 85.0,
                'mode': 0.5,                # ä¸­æ€§è°ƒå¼ï¼Œå¤æ‚æƒ…æ„Ÿ
                'dynamics': 0.5,
                'harmony_consonance': 0.6,
                'timbre_preference': 'vintage_warmth',
                'pitch_register': 0.5,
                'density': 0.4,
                'emotional_envelope_direction': 'nostalgic_wave'
            },
            priority="medium"
        ))
        
        # Lowçº§åˆ«è§„åˆ™ (è½»å¾®æƒ…ç»ªçŠ¶æ€)
        
        # 10. è½»å¾®æ— èŠ â†’ å…´è¶£æ¿€å‘
        self.rules.append(MusicRule(
            name="å…´è¶£æ¿€å‘",
            conditions={"æ— èŠ": 0.4},
            parameters={
                'tempo': 95.0,
                'mode': 0.6,
                'dynamics': 0.6,
                'harmony_consonance': 0.6,
                'timbre_preference': 'interesting_textures',
                'pitch_register': 0.6,
                'density': 0.5,
                'emotional_envelope_direction': 'engaging'
            },
            priority="low"
        ))
        
        logger.info(f"ğŸ“š GEMSè§„åˆ™ç³»ç»ŸåŠ è½½å®Œæˆ: {len(self.rules)} æ¡è§„åˆ™")
    
    def _vector_to_emotion_dict(self, emotion_vector: np.ndarray) -> Dict[str, float]:
        """
        å°†27ç»´æƒ…ç»ªå‘é‡è½¬æ¢ä¸ºæƒ…ç»ªå­—å…¸
        
        Args:
            emotion_vector: é•¿åº¦ä¸º27çš„numpyæ•°ç»„
            
        Returns:
            æƒ…ç»ªå­—å…¸ {"æƒ…ç»ªå": å¼ºåº¦å€¼}
        """
        if len(emotion_vector) != 27:
            raise ValueError(f"æƒ…ç»ªå‘é‡ç»´åº¦å¿…é¡»ä¸º27ï¼Œå½“å‰ä¸º{len(emotion_vector)}")
        
        emotion_dict = {}
        for i, emotion_name in enumerate(self.emotion_names):
            emotion_dict[emotion_name] = float(emotion_vector[i])
        
        return emotion_dict
    
    def _evaluate_condition(self, emotion_dict: Dict[str, float], 
                          condition: Dict[str, float]) -> bool:
        """
        è¯„ä¼°æƒ…ç»ªæ¡ä»¶æ˜¯å¦æ»¡è¶³
        
        Args:
            emotion_dict: å½“å‰æƒ…ç»ªçŠ¶æ€
            condition: è§„åˆ™æ¡ä»¶
            
        Returns:
            æ˜¯å¦æ»¡è¶³æ¡ä»¶
        """
        for emotion_name, threshold in condition.items():
            if emotion_name not in emotion_dict:
                return False
            if emotion_dict[emotion_name] < threshold:
                return False
        return True
    
    def get_initial_music_parameters(self, emotion_vector: np.ndarray) -> Dict[str, Any]:
        """
        æ ¹æ®27ç»´æƒ…ç»ªå‘é‡è·å–åˆå§‹éŸ³ä¹å‚æ•°
        
        è¿™æ˜¯çŸ¥è¯†å›¾è°±çš„æ ¸å¿ƒæ–¹æ³•ï¼ŒåŸºäºGEMSæ¨¡å‹å’ŒISOåŸåˆ™
        
        Args:
            emotion_vector: é•¿åº¦ä¸º27çš„numpyæ•°ç»„ï¼Œå–å€¼èŒƒå›´[0,1]
            
        Returns:
            éŸ³ä¹å‚æ•°å­—å…¸ï¼ŒåŒ…å«ï¼š
            - tempo: èŠ‚æ‹ (BPM)
            - mode: è°ƒå¼ (0=å°è°ƒ, 1=å¤§è°ƒ)
            - dynamics: éŸ³é‡åŠ¨æ€ (0=è½», 1=å“)
            - harmony_consonance: å’Œå£°åå’Œåº¦ (0=ä¸åå’Œ, 1=åå’Œ)
            - timbre_preference: éŸ³è‰²åå¥½
            - pitch_register: éŸ³åŸŸ (0=ä½, 1=é«˜)
            - density: å¯†åº¦ (0=ç¨€ç–, 1=å¯†é›†)
            - emotional_envelope_direction: æƒ…ç»ªåŒ…ç»œæ–¹å‘
        """
        try:
            # éªŒè¯è¾“å…¥
            if not isinstance(emotion_vector, np.ndarray):
                emotion_vector = np.array(emotion_vector)
            
            if emotion_vector.shape[0] != 27:
                raise ValueError(f"æƒ…ç»ªå‘é‡ç»´åº¦é”™è¯¯: æœŸæœ›27ç»´ï¼Œå®é™…{emotion_vector.shape[0]}ç»´")
            
            # æ•°å€¼èŒƒå›´æ£€æŸ¥
            if np.any(emotion_vector < 0) or np.any(emotion_vector > 1):
                logger.warning("âš ï¸  æƒ…ç»ªå‘é‡å€¼è¶…å‡º[0,1]èŒƒå›´ï¼Œå°†è¿›è¡Œè£å‰ª")
                emotion_vector = np.clip(emotion_vector, 0, 1)
            
            # è½¬æ¢ä¸ºæƒ…ç»ªå­—å…¸
            emotion_dict = self._vector_to_emotion_dict(emotion_vector)
            
            # åˆ†æä¸»è¦æƒ…ç»ª
            primary_emotions = sorted(emotion_dict.items(), key=lambda x: x[1], reverse=True)[:3]
            logger.info(f"ğŸ§  ä¸»è¦æƒ…ç»ªçŠ¶æ€: {[(name, f'{value:.3f}') for name, value in primary_emotions]}")
            
            # è¯„ä¼°æ‰€æœ‰è§„åˆ™å¹¶æ‰¾åˆ°æœ€ä½³åŒ¹é…
            best_rule = None
            best_match_strength = 0.0
            matched_rules = []
            
            for rule in self.rules:
                is_match, match_strength = rule.evaluate(emotion_dict)
                if is_match:
                    matched_rules.append((rule, match_strength))
                    if match_strength > best_match_strength:
                        best_match_strength = match_strength
                        best_rule = rule
            
            # å¼€å§‹æ„å»ºéŸ³ä¹å‚æ•°
            music_params = self.default_music_parameters.copy()
            
            if best_rule:
                # åº”ç”¨æœ€ä½³åŒ¹é…è§„åˆ™
                logger.info(f"ğŸ¯ åŒ¹é…è§„åˆ™: {best_rule.name} (ä¼˜å…ˆçº§: {best_rule.priority}, å¼ºåº¦: {best_match_strength:.3f})")
                
                for param_name, param_value in best_rule.parameters.items():
                    music_params[param_name] = param_value
                
                # è®°å½•æ‰€æœ‰åŒ¹é…çš„è§„åˆ™
                if len(matched_rules) > 1:
                    logger.info(f"ğŸ“‹ å…¶ä»–åŒ¹é…è§„åˆ™: {[(rule.name, f'{strength:.3f}') for rule, strength in matched_rules if rule != best_rule]}")
            
            else:
                logger.info("ğŸ” æœªæ‰¾åˆ°åŒ¹é…è§„åˆ™ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
                
                # åŸºäºæƒ…ç»ªå¼ºåº¦è¿›è¡ŒåŸºç¡€è°ƒæ•´
                max_emotion_name, max_emotion_value = primary_emotions[0]
                
                if max_emotion_value > 0.3:  # æœ‰æ˜æ˜¾æƒ…ç»ª
                    # åŸºç¡€æƒ…ç»ªè°ƒæ•´é€»è¾‘
                    if max_emotion_name in ["ç„¦è™‘", "ææƒ§", "ææ€–"]:
                        music_params['tempo'] = max(50, music_params['tempo'] - 20)
                        music_params['harmony_consonance'] = 0.8
                        music_params['dynamics'] = 0.3
                    elif max_emotion_name in ["å¿«ä¹", "å…´å¥‹", "å¨±ä¹"]:
                        music_params['tempo'] = min(120, music_params['tempo'] + 20) 
                        music_params['mode'] = 0.8
                        music_params['dynamics'] = 0.7
                    elif max_emotion_name in ["æ‚²ä¼¤", "å¤±æœ›", "æ€€æ—§"]:
                        music_params['tempo'] = max(60, music_params['tempo'] - 10)
                        music_params['mode'] = 0.3
                        
                    logger.info(f"ğŸ”§ åŸºäº{max_emotion_name}({max_emotion_value:.3f})è¿›è¡ŒåŸºç¡€è°ƒæ•´")
            
            # ç¡®ä¿å‚æ•°åœ¨åˆç†èŒƒå›´å†…
            music_params['tempo'] = max(40, min(160, music_params['tempo']))
            music_params['mode'] = max(0, min(1, music_params['mode']))
            music_params['dynamics'] = max(0, min(1, music_params['dynamics']))
            music_params['harmony_consonance'] = max(0, min(1, music_params['harmony_consonance']))
            music_params['pitch_register'] = max(0, min(1, music_params['pitch_register']))
            music_params['density'] = max(0, min(1, music_params['density']))
            
            logger.info(f"ğŸµ æœ€ç»ˆéŸ³ä¹å‚æ•°: Tempo={music_params['tempo']:.1f}, Mode={music_params['mode']:.2f}, Dynamics={music_params['dynamics']:.2f}")
            
            return music_params
            
        except Exception as e:
            logger.error(f"âŒ è·å–éŸ³ä¹å‚æ•°å¤±è´¥: {e}")
            logger.info("ğŸ”„ è¿”å›é»˜è®¤å‚æ•°")
            return self.default_music_parameters.copy()
    
    def get_music_search_parameters(self, emotion_vector: np.ndarray) -> Dict[str, Any]:
        """
        è·å–é€‚ç”¨äºMI_retrieveæ¨¡å—çš„æœç´¢å‚æ•°
        
        Args:
            emotion_vector: 27ç»´æƒ…ç»ªå‘é‡
            
        Returns:
            åŒ…å«æ–‡æœ¬æè¿°ã€ç»“æ„åŒ–å‚æ•°å’Œæƒ…ç»ªä¸Šä¸‹æ–‡çš„å­—å…¸
        """
        try:
            # è·å–éŸ³ä¹å‚æ•°
            music_params = self.get_initial_music_parameters(emotion_vector)
            
            # åˆ†ææƒ…ç»ªä¸Šä¸‹æ–‡
            emotion_dict = self._vector_to_emotion_dict(emotion_vector)
            primary_emotions = sorted(emotion_dict.items(), key=lambda x: x[1], reverse=True)[:3]
            primary_emotions = [(name, value) for name, value in primary_emotions if value > 0.1]
            
            # è®¡ç®—æƒ…ç»ªå¼ºåº¦
            emotion_intensity = np.mean([value for _, value in primary_emotions]) if primary_emotions else 0.0
            
            # ç”Ÿæˆæ–‡æœ¬æè¿°
            text_description = self._generate_text_description(music_params)
            
            # æ„å»ºç»“æ„åŒ–å‚æ•°
            structured_params = {
                "tempo": music_params['tempo'],
                "mode": "major" if music_params['mode'] > 0.6 else "minor" if music_params['mode'] < 0.4 else "neutral",
                "dynamics": "loud" if music_params['dynamics'] > 0.7 else "soft" if music_params['dynamics'] < 0.3 else "medium",
                "harmony": "consonant" if music_params['harmony_consonance'] > 0.7 else "dissonant" if music_params['harmony_consonance'] < 0.3 else "mixed",
                "timbre": music_params['timbre_preference'],
                "register": "high" if music_params['pitch_register'] > 0.7 else "low" if music_params['pitch_register'] < 0.3 else "medium",
                "density": "dense" if music_params['density'] > 0.7 else "sparse" if music_params['density'] < 0.3 else "medium"
            }
            
            return {
                "text_description": text_description,
                "structured_params": structured_params,
                "emotion_context": {
                    "primary_emotions": [name for name, _ in primary_emotions],
                    "emotion_intensity": emotion_intensity,
                    "emotion_details": dict(primary_emotions)
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæœç´¢å‚æ•°å¤±è´¥: {e}")
            return {
                "text_description": "èŠ‚æ‹é€‚ä¸­ï¼Œè°ƒå¼ä¸­æ€§ï¼ŒéŸ³è‰²æ¸©å’Œï¼Œé€‚åˆæ”¾æ¾",
                "structured_params": {"tempo": 80, "mode": "neutral", "dynamics": "medium"},
                "emotion_context": {"primary_emotions": [], "emotion_intensity": 0.0}
            }
    
    def _generate_text_description(self, music_params: Dict[str, Any]) -> str:
        """
        æ ¹æ®éŸ³ä¹å‚æ•°ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°
        
        Args:
            music_params: éŸ³ä¹å‚æ•°å­—å…¸
            
        Returns:
            è‡ªç„¶è¯­è¨€æè¿°å­—ç¬¦ä¸²
        """
        # èŠ‚æ‹æè¿°
        tempo = music_params['tempo']
        if tempo < 60:
            tempo_desc = f"å»ºè®®åˆå§‹èŠ‚æ‹ä¸º {tempo:.0f} BPMï¼ŒèŠ‚å¥éå¸¸ç¼“æ…¢"
        elif tempo < 80:
            tempo_desc = f"å»ºè®®åˆå§‹èŠ‚æ‹ä¸º {tempo:.0f} BPMï¼ŒèŠ‚å¥ç¼“æ…¢æ”¾æ¾"
        elif tempo < 100:
            tempo_desc = f"å»ºè®®åˆå§‹èŠ‚æ‹ä¸º {tempo:.0f} BPMï¼ŒèŠ‚å¥é€‚ä¸­ç¨³å®š"
        elif tempo < 120:
            tempo_desc = f"å»ºè®®åˆå§‹èŠ‚æ‹ä¸º {tempo:.0f} BPMï¼ŒèŠ‚å¥æ˜å¿«æ´»æ³¼"
        else:
            tempo_desc = f"å»ºè®®åˆå§‹èŠ‚æ‹ä¸º {tempo:.0f} BPMï¼ŒèŠ‚å¥å¿«é€Ÿæœ‰åŠ›"
        
        # è°ƒå¼æè¿°
        mode = music_params['mode']
        if mode > 0.7:
            mode_desc = "è°ƒå¼å€¾å‘å¤§è°ƒï¼Œæ˜äº®ç§¯æ"
        elif mode < 0.3:
            mode_desc = "è°ƒå¼å€¾å‘å°è°ƒï¼Œæ·±æ²‰å†…æ•›"
        else:
            mode_desc = "è°ƒå¼ä¸­æ€§æˆ–è°ƒå¼å˜åŒ–ä¸°å¯Œ"
        
        # å’Œå£°æè¿°
        harmony = music_params['harmony_consonance']
        if harmony > 0.8:
            harmony_desc = "å’Œå£°é«˜åº¦åå’Œï¼Œçº¯å‡€å®‰å…¨"
        elif harmony > 0.6:
            harmony_desc = "å’Œå£°ç›¸å¯¹åå’Œï¼Œæ¸©æš–ç¨³å®š"
        elif harmony < 0.3:
            harmony_desc = "å’Œå£°åŒ…å«ä¸åå’Œï¼Œè¡¨ç°åŠ›å¼º"
        else:
            harmony_desc = "å’Œå£°å¤æ‚å¤šå˜ï¼Œå±‚æ¬¡ä¸°å¯Œ"
        
        # éŸ³è‰²æè¿°
        timbre = music_params['timbre_preference']
        timbre_mapping = {
            'neutral_pad': 'éŸ³è‰²ä¸­æ€§æŸ”å’Œ',
            'warm_pad': 'éŸ³è‰²æ¸©æš–åŒ…å®¹',
            'soft_choir': 'éŸ³è‰²è½»æŸ”å¦‚æ­Œ',
            'gentle_piano': 'éŸ³è‰²æ¸…é›…å¦‚é’¢ç´',
            'nature_sounds': 'éŸ³è‰²è‡ªç„¶æ¸…æ–°',
            'ambient_pad': 'éŸ³è‰²ç¯å¢ƒåŒ–æ°›å›´',
            'bright_ensemble': 'éŸ³è‰²æ˜äº®ä¸°å¯Œ',
            'energetic_mix': 'éŸ³è‰²å……æ»¡æ´»åŠ›',
            'expressive_strings': 'éŸ³è‰²è¡¨ç°åŠ›å¼º',
            'vintage_warmth': 'éŸ³è‰²æ€€æ—§æ¸©æš–',
            'interesting_textures': 'éŸ³è‰²å¯Œæœ‰è´¨æ„Ÿ'
        }
        timbre_desc = timbre_mapping.get(timbre, 'éŸ³è‰²ç‰¹è‰²é²œæ˜')
        
        # åŠ¨æ€æè¿°
        dynamics = music_params['dynamics']
        if dynamics > 0.8:
            dynamics_desc = "éŸ³é‡é¥±æ»¡æœ‰åŠ›"
        elif dynamics > 0.6:
            dynamics_desc = "éŸ³é‡é€‚ä¸­æ¸…æ™°"
        elif dynamics < 0.3:
            dynamics_desc = "éŸ³é‡è½»æŸ”ç»†è…»"
        else:
            dynamics_desc = "éŸ³é‡å˜åŒ–è‡ªç„¶"
        
        # éŸ³åŸŸæè¿°
        register = music_params['pitch_register']
        if register > 0.7:
            register_desc = "éŸ³åŸŸåé«˜ï¼Œæ˜äº®æ¸…é€"
        elif register < 0.3:
            register_desc = "éŸ³åŸŸåä½ï¼Œæ·±æ²‰ç¨³é‡"
        else:
            register_desc = "éŸ³åŸŸé€‚ä¸­ï¼Œå¹³è¡¡èˆ’é€‚"
        
        # ç»„åˆæè¿°
        description = f"{tempo_desc}ï¼Œ{mode_desc}ï¼Œ{harmony_desc}ï¼Œ{timbre_desc}ï¼Œ{dynamics_desc}ï¼Œ{register_desc}"
        
        return description
    
    def analyze_emotion_vector(self, emotion_vector: np.ndarray) -> Dict[str, Any]:
        """
        åˆ†ææƒ…ç»ªå‘é‡çš„è¯¦ç»†ä¿¡æ¯
        
        Args:
            emotion_vector: 27ç»´æƒ…ç»ªå‘é‡
            
        Returns:
            æƒ…ç»ªåˆ†æç»“æœ
        """
        emotion_dict = self._vector_to_emotion_dict(emotion_vector)
        
        # æ’åºå¹¶åˆ†æ
        sorted_emotions = sorted(emotion_dict.items(), key=lambda x: x[1], reverse=True)
        
        # æ‰¾å‡ºæ˜¾è‘—æƒ…ç»ª (> 0.3)
        significant_emotions = [(name, value) for name, value in sorted_emotions if value > 0.3]
        
        # æƒ…ç»ªåˆ†ç±»
        positive_emotions = ["å¿«ä¹", "å…´å¥‹", "å¨±ä¹", "é’¦ä½©", "å´‡æ‹œ", "å®¡ç¾æ¬£èµ", "æ•¬ç•", "å…¥è¿·", "å…´è¶£", "æµªæ¼«"]
        negative_emotions = ["æ„¤æ€’", "ç„¦è™‘", "æ‚²ä¼¤", "ææƒ§", "å†…ç–š", "ææ€–", "å¤±æœ›", "åŒæ¶", "å«‰å¦’", "è”‘è§†"]
        neutral_emotions = ["å¹³é™", "æ— èŠ", "å›°æƒ‘", "å°´å°¬", "åŒæƒ…", "æ¸´æœ›", "æ€€æ—§"]
        
        positive_score = sum(emotion_dict[e] for e in positive_emotions if e in emotion_dict)
        negative_score = sum(emotion_dict[e] for e in negative_emotions if e in emotion_dict)
        neutral_score = sum(emotion_dict[e] for e in neutral_emotions if e in emotion_dict)
        
        return {
            "top_emotions": sorted_emotions[:5],
            "significant_emotions": significant_emotions,
            "emotion_balance": {
                "positive": positive_score,
                "negative": negative_score,
                "neutral": neutral_score
            },
            "overall_intensity": np.mean(emotion_vector),
            "max_emotion": sorted_emotions[0],
            "emotion_diversity": len(significant_emotions)
        }

def main():
    """æ¼”ç¤ºçŸ¥è¯†å›¾è°±çš„ä½¿ç”¨"""
    print("ğŸ§  æƒ…ç»ª-éŸ³ä¹çŸ¥è¯†å›¾è°±æ¼”ç¤º")
    print("=" * 50)
    
    # åˆå§‹åŒ–çŸ¥è¯†å›¾è°±
    kg = KnowledgeGraph()
    
    # æµ‹è¯•åœºæ™¯1: é«˜ç„¦è™‘çŠ¶æ€
    print("\nğŸ” æµ‹è¯•åœºæ™¯1: é«˜ç„¦è™‘çŠ¶æ€")
    anxiety_vector = np.zeros(27)
    anxiety_vector[5] = 0.8  # ç„¦è™‘
    anxiety_vector[9] = 0.1  # å¹³é™
    
    result1 = kg.get_music_search_parameters(anxiety_vector)
    print("æƒ…ç»ªåˆ†æ:", result1["emotion_context"])
    print("éŸ³ä¹æè¿°:", result1["text_description"])
    
    # æµ‹è¯•åœºæ™¯2: é«˜å¹³é™çŠ¶æ€
    print("\nğŸ” æµ‹è¯•åœºæ™¯2: é«˜å¹³é™çŠ¶æ€")
    calm_vector = np.zeros(27)
    calm_vector[9] = 0.9   # å¹³é™
    
    result2 = kg.get_music_search_parameters(calm_vector)
    print("æƒ…ç»ªåˆ†æ:", result2["emotion_context"])
    print("éŸ³ä¹æè¿°:", result2["text_description"])
    
    # æµ‹è¯•åœºæ™¯3: å¿«ä¹å…´å¥‹æ··åˆ
    print("\nğŸ” æµ‹è¯•åœºæ™¯3: å¿«ä¹å…´å¥‹çŠ¶æ€")
    happy_vector = np.zeros(27)
    happy_vector[23] = 0.8  # å¿«ä¹
    happy_vector[18] = 0.6  # å…´å¥‹
    
    result3 = kg.get_music_search_parameters(happy_vector)
    print("æƒ…ç»ªåˆ†æ:", result3["emotion_context"])
    print("éŸ³ä¹æè¿°:", result3["text_description"])
    
    print("\nâœ… çŸ¥è¯†å›¾è°±æ¼”ç¤ºå®Œæˆ!")

if __name__ == "__main__":
    main()