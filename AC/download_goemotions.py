#!/usr/bin/env python3
"""
ä¸‹è½½å’Œé¢„å¤„ç†GoEmotionsæ•°æ®é›†

ä»Google Research GitHubä»“åº“ä¸‹è½½GoEmotionsæ•°æ®
å¹¶è½¬æ¢ä¸ºé€‚åˆè®­ç»ƒçš„æ ¼å¼
"""

import os
import requests
import pandas as pd
import numpy as np
import logging
from pathlib import Path
from typing import Dict, List
import json

from config import DATA_PATHS, GOEMOTIONS_LABELS, GOEMOTIONS_TO_CK_MAPPING, COWEN_KELTNER_EMOTIONS

logger = logging.getLogger(__name__)

class GoEmotionsDownloader:
    """GoEmotionsæ•°æ®é›†ä¸‹è½½å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ä¸‹è½½å™¨"""
        self.base_url = "https://raw.githubusercontent.com/google-research/google-research/master/goemotions/data/"
        self.data_dir = Path(__file__).parent / "data"
        self.data_dir.mkdir(exist_ok=True)
        
        # æ–‡ä»¶æ˜ å°„
        self.files = {
            "train": "train.tsv",
            "dev": "dev.tsv", 
            "test": "test.tsv",
            "emotions": "emotions.txt"
        }
        
        logger.info("âœ… GoEmotionsä¸‹è½½å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def download_files(self) -> bool:
        """
        ä¸‹è½½GoEmotionsæ•°æ®æ–‡ä»¶
        
        Returns:
            bool: æ˜¯å¦ä¸‹è½½æˆåŠŸ
        """
        try:
            logger.info("ğŸ“¥ å¼€å§‹ä¸‹è½½GoEmotionsæ•°æ®é›†...")
            
            for split, filename in self.files.items():
                url = self.base_url + filename
                local_path = self.data_dir / filename
                
                if local_path.exists():
                    logger.info(f"   âœ“ {filename} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
                    continue
                
                logger.info(f"   ğŸ“¥ ä¸‹è½½ {filename}...")
                
                response = requests.get(url, timeout=30)
                response.raise_for_status()
                
                with open(local_path, 'wb') as f:
                    f.write(response.content)
                
                logger.info(f"   âœ… {filename} ä¸‹è½½å®Œæˆ ({len(response.content)/1024:.1f} KB)")
            
            logger.info("âœ… æ‰€æœ‰æ–‡ä»¶ä¸‹è½½å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def parse_tsv_data(self, file_path: Path) -> pd.DataFrame:
        """
        è§£æTSVæ ¼å¼çš„GoEmotionsæ•°æ®
        
        Args:
            file_path: TSVæ–‡ä»¶è·¯å¾„
            
        Returns:
            è§£æåçš„DataFrame
        """
        try:
            logger.info(f"ğŸ“Š è§£ææ•°æ®æ–‡ä»¶: {file_path.name}")
            
            # GoEmotions TSVæ ¼å¼: [text, emotion_ids, id]
            df = pd.read_csv(file_path, sep='\t', header=None, 
                           names=['text', 'emotion_ids', 'id'])
            
            logger.info(f"   åŸå§‹æ•°æ®: {len(df)} æ¡è®°å½•")
            
            # æ¸…ç†æ•°æ®
            df = df.dropna(subset=['text', 'emotion_ids'])
            df['text'] = df['text'].astype(str).str.strip()
            df = df[df['text'].str.len() > 0]
            
            logger.info(f"   æ¸…ç†åæ•°æ®: {len(df)} æ¡è®°å½•")
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®è§£æå¤±è´¥: {e}")
            return pd.DataFrame()
    
    def convert_to_multilabel_format(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å°†GoEmotionsæ•°æ®è½¬æ¢ä¸ºå¤šæ ‡ç­¾æ ¼å¼
        
        Args:
            df: åŸå§‹æ•°æ®DataFrame
            
        Returns:
            å¤šæ ‡ç­¾æ ¼å¼çš„DataFrame
        """
        try:
            logger.info("ğŸ”„ è½¬æ¢ä¸ºå¤šæ ‡ç­¾æ ¼å¼...")
            
            # åˆ›å»ºç»“æœDataFrame
            result_data = []
            
            for idx, row in df.iterrows():
                text = row['text']
                emotion_ids = row['emotion_ids']
                
                # è§£ææƒ…ç»ªID
                if pd.isna(emotion_ids) or emotion_ids == '':
                    continue
                
                # å¤„ç†æƒ…ç»ªIDåˆ—è¡¨
                try:
                    if isinstance(emotion_ids, str):
                        # æ ¼å¼å¯èƒ½æ˜¯ "1,5,12" æˆ– "[1,5,12]"
                        emotion_ids = emotion_ids.strip('[]')
                        if emotion_ids:
                            emotion_id_list = [int(x.strip()) for x in emotion_ids.split(',') if x.strip()]
                        else:
                            continue
                    else:
                        emotion_id_list = [int(emotion_ids)]
                except (ValueError, TypeError):
                    logger.warning(f"âš ï¸  æ— æ³•è§£ææƒ…ç»ªID: {emotion_ids}")
                    continue
                
                # åˆ›å»ºå¤šæ ‡ç­¾å‘é‡ (27ç»´GoEmotionsæ ‡ç­¾)
                label_vector = [0.0] * len(GOEMOTIONS_LABELS)
                
                for emotion_id in emotion_id_list:
                    if 0 <= emotion_id < len(GOEMOTIONS_LABELS):
                        label_vector[emotion_id] = 1.0
                
                # æ„å»ºæ•°æ®è¡Œ
                data_row = {'text': text}
                for i, label in enumerate(GOEMOTIONS_LABELS):
                    data_row[label] = label_vector[i]
                
                result_data.append(data_row)
            
            result_df = pd.DataFrame(result_data)
            logger.info(f"âœ… å¤šæ ‡ç­¾è½¬æ¢å®Œæˆ: {len(result_df)} æ¡è®°å½•")
            
            # ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
            label_counts = {}
            for label in GOEMOTIONS_LABELS:
                if label in result_df.columns:
                    label_counts[label] = int(result_df[label].sum())
            
            logger.info("ğŸ“Š æ ‡ç­¾åˆ†å¸ƒç»Ÿè®¡:")
            sorted_labels = sorted(label_counts.items(), key=lambda x: x[1], reverse=True)
            for label, count in sorted_labels[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                logger.info(f"   {label}: {count}")
            
            return result_df
            
        except Exception as e:
            logger.error(f"âŒ å¤šæ ‡ç­¾è½¬æ¢å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def convert_to_ck_format(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å°†GoEmotionsæ ¼å¼è½¬æ¢ä¸ºCowen & Keltner 27ç»´æ ¼å¼
        
        Args:
            df: GoEmotionså¤šæ ‡ç­¾æ ¼å¼DataFrame
            
        Returns:
            C&K 27ç»´æ ¼å¼DataFrame
        """
        try:
            logger.info("ğŸ”„ è½¬æ¢ä¸ºC&K 27ç»´æ ¼å¼...")
            
            # å¯¼å…¥æ˜ å°„å™¨
            from emotion_mapper import GoEmotionsMapper
            mapper = GoEmotionsMapper()
            
            result_data = []
            conversion_stats = {ck_emotion: 0 for ck_emotion in COWEN_KELTNER_EMOTIONS}
            
            for idx, row in df.iterrows():
                text = row['text']
                
                # æå–GoEmotionsåˆ†æ•°
                ge_scores = {}
                for label in GOEMOTIONS_LABELS:
                    if label in row:
                        ge_scores[label] = float(row[label])
                
                # æ˜ å°„åˆ°C&Kå‘é‡
                ck_vector = mapper.map_goemotions_to_ck_vector(ge_scores)
                
                # æ„å»ºæ•°æ®è¡Œ
                data_row = {'text': text}
                
                # æ·»åŠ C&Kæƒ…ç»ªåˆ—
                for i, emotion in enumerate(COWEN_KELTNER_EMOTIONS):
                    data_row[emotion] = float(ck_vector[i])
                    if ck_vector[i] > 0:
                        conversion_stats[emotion] += 1
                
                # æ·»åŠ å…ƒæ•°æ®
                active_ge_labels = [label for label, score in ge_scores.items() if score > 0]
                data_row['original_goemotions'] = ','.join(active_ge_labels)
                data_row['max_emotion'] = COWEN_KELTNER_EMOTIONS[np.argmax(ck_vector)]
                data_row['emotion_intensity'] = float(np.max(ck_vector))
                data_row['total_intensity'] = float(np.sum(ck_vector))
                
                result_data.append(data_row)
                
                if (idx + 1) % 1000 == 0:
                    logger.info(f"   è½¬æ¢è¿›åº¦: {idx + 1}/{len(df)}")
            
            result_df = pd.DataFrame(result_data)
            logger.info(f"âœ… C&Kæ ¼å¼è½¬æ¢å®Œæˆ: {len(result_df)} æ¡è®°å½•")
            
            # ç»Ÿè®¡C&Kæƒ…ç»ªåˆ†å¸ƒ
            logger.info("ğŸ“Š C&Kæƒ…ç»ªåˆ†å¸ƒç»Ÿè®¡:")
            sorted_ck = sorted(conversion_stats.items(), key=lambda x: x[1], reverse=True)
            for emotion, count in sorted_ck[:10]:
                logger.info(f"   {emotion}: {count}")
            
            return result_df
            
        except Exception as e:
            logger.error(f"âŒ C&Kæ ¼å¼è½¬æ¢å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def process_and_save_data(self) -> bool:
        """
        å¤„ç†å¹¶ä¿å­˜æ‰€æœ‰æ•°æ®
        
        Returns:
            bool: æ˜¯å¦å¤„ç†æˆåŠŸ
        """
        try:
            logger.info("ğŸ”„ å¼€å§‹å¤„ç†å’Œä¿å­˜æ•°æ®...")
            
            splits = ['train', 'dev', 'test']
            
            for split in splits:
                logger.info(f"\nğŸ“Š å¤„ç† {split} æ•°æ®é›†...")
                
                # è¯»å–åŸå§‹TSVæ–‡ä»¶
                tsv_file = self.data_dir / f"{split}.tsv"
                if not tsv_file.exists():
                    logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {tsv_file}")
                    continue
                
                # è§£æTSVæ•°æ®
                df = self.parse_tsv_data(tsv_file)
                if df.empty:
                    logger.error(f"âŒ {split} æ•°æ®è§£æå¤±è´¥")
                    continue
                
                # è½¬æ¢ä¸ºå¤šæ ‡ç­¾æ ¼å¼
                multilabel_df = self.convert_to_multilabel_format(df)
                if multilabel_df.empty:
                    logger.error(f"âŒ {split} å¤šæ ‡ç­¾è½¬æ¢å¤±è´¥")
                    continue
                
                # ä¿å­˜GoEmotionsæ ¼å¼
                ge_output_path = self.data_dir / f"goemotions_{split}.csv"
                multilabel_df.to_csv(ge_output_path, index=False, encoding='utf-8')
                logger.info(f"âœ… GoEmotionsæ ¼å¼ä¿å­˜: {ge_output_path}")
                
                # è½¬æ¢ä¸ºC&Kæ ¼å¼
                ck_df = self.convert_to_ck_format(multilabel_df)
                if ck_df.empty:
                    logger.error(f"âŒ {split} C&Kè½¬æ¢å¤±è´¥")
                    continue
                
                # ä¿å­˜C&Kæ ¼å¼
                ck_output_path = self.data_dir / f"processed_{split}.csv"
                ck_df.to_csv(ck_output_path, index=False, encoding='utf-8')
                logger.info(f"âœ… C&Kæ ¼å¼ä¿å­˜: {ck_output_path}")
            
            logger.info("\nâœ… æ‰€æœ‰æ•°æ®å¤„ç†å®Œæˆ!")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®å¤„ç†å¤±è´¥: {e}")
            return False
    
    def generate_dataset_summary(self) -> Dict:
        """
        ç”Ÿæˆæ•°æ®é›†æ‘˜è¦ä¿¡æ¯
        
        Returns:
            æ•°æ®é›†æ‘˜è¦å­—å…¸
        """
        try:
            summary = {
                "dataset_name": "GoEmotions",
                "source": "Google Research",
                "emotion_taxonomy": "Cowen & Keltner (2017) 27 dimensions",
                "splits": {},
                "mapping_info": {
                    "original_labels": len(GOEMOTIONS_LABELS),
                    "target_emotions": len(COWEN_KELTNER_EMOTIONS),
                    "mapping_coverage": len(GOEMOTIONS_TO_CK_MAPPING) / len(GOEMOTIONS_LABELS)
                }
            }
            
            # ç»Ÿè®¡å„åˆ†å‰²çš„ä¿¡æ¯
            for split in ['train', 'dev', 'test']:
                ck_file = self.data_dir / f"processed_{split}.csv"
                if ck_file.exists():
                    df = pd.read_csv(ck_file)
                    
                    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                    emotion_columns = [col for col in df.columns if col in COWEN_KELTNER_EMOTIONS]
                    emotion_matrix = df[emotion_columns].values
                    
                    summary["splits"][split] = {
                        "samples": len(df),
                        "avg_emotions_per_sample": float(np.mean(np.sum(emotion_matrix > 0, axis=1))),
                        "avg_total_intensity": float(np.mean(np.sum(emotion_matrix, axis=1))),
                        "most_common_emotion": emotion_columns[np.argmax(np.sum(emotion_matrix, axis=0))]
                    }
            
            # ä¿å­˜æ‘˜è¦
            summary_path = self.data_dir / "dataset_summary.json"
            with open(summary_path, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            logger.info(f"âœ… æ•°æ®é›†æ‘˜è¦ä¿å­˜: {summary_path}")
            return summary
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæ‘˜è¦å¤±è´¥: {e}")
            return {}

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ GoEmotionsæ•°æ®é›†ä¸‹è½½å’Œé¢„å¤„ç†")
    print("=" * 50)
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    # åˆå§‹åŒ–ä¸‹è½½å™¨
    downloader = GoEmotionsDownloader()
    
    # ä¸‹è½½æ–‡ä»¶
    if not downloader.download_files():
        print("âŒ æ•°æ®ä¸‹è½½å¤±è´¥")
        return False
    
    # å¤„ç†æ•°æ®
    if not downloader.process_and_save_data():
        print("âŒ æ•°æ®å¤„ç†å¤±è´¥")
        return False
    
    # ç”Ÿæˆæ‘˜è¦
    summary = downloader.generate_dataset_summary()
    if summary:
        print("\nğŸ“Š æ•°æ®é›†æ‘˜è¦:")
        for split, info in summary.get("splits", {}).items():
            print(f"   {split}: {info['samples']} æ ·æœ¬, å¹³å‡{info['avg_emotions_per_sample']:.1f}ä¸ªæƒ…ç»ª")
    
    print("\nğŸ‰ GoEmotionsæ•°æ®é›†å‡†å¤‡å®Œæˆ!")
    print("ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒxlm-robertaæ¨¡å‹äº†ï¼")
    
    return True

if __name__ == "__main__":
    success = main()
    if not success:
        exit(1)