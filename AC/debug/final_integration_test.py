#!/usr/bin/env python3
"""
ACæƒ…æ„Ÿåˆ†æžæ¨¡å—æœ€ç»ˆé›†æˆæµ‹è¯•

éªŒè¯ä¿®å¤åŽçš„ACæ¨¡å—èƒ½å¤Ÿï¼š
1. æ­£ç¡®è¯†åˆ«ä¸åŒæƒ…æ„Ÿ
2. è¾“å‡º27ç»´æ ‡å‡†åŒ–å‘é‡  
3. ä¸ŽKGæ¨¡å—å®Œç¾Žé›†æˆ
4. å¤„ç†å¤šç§è¯­è¨€å’Œæƒ…æ„Ÿ
"""

import sys
import numpy as np
from pathlib import Path

# æ·»åŠ ACæ¨¡å—è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

def test_emotion_diversity():
    """æµ‹è¯•æƒ…æ„Ÿè¯†åˆ«çš„å¤šæ ·æ€§å’Œå‡†ç¡®æ€§"""
    print("ðŸŽ­ æµ‹è¯•æƒ…æ„Ÿè¯†åˆ«å¤šæ ·æ€§å’Œå‡†ç¡®æ€§")
    print("-" * 50)
    
    from inference_api import analyze_text_emotion
    
    # è®¾è®¡çš„æµ‹è¯•ç”¨ä¾‹ - æ¶µç›–ä¸åŒæƒ…æ„Ÿç±»åž‹
    test_cases = [
        {
            'category': 'å¼ºçƒˆæ­£é¢æƒ…æ„Ÿ',
            'texts': [
                "ä»Šå¤©æ˜¯æˆ‘äººç”Ÿä¸­æœ€å¼€å¿ƒçš„ä¸€å¤©ï¼æˆ‘ä¸­äº†å½©ç¥¨ï¼",
                "è¿™ä¸ªéŸ³ä¹ä¼šå¤ªä»¤äººå…´å¥‹äº†ï¼Œæˆ‘ç®€ç›´ä¸æ•¢ç›¸ä¿¡ï¼", 
                "çœ‹åˆ°å­©å­ä»¬å¤©çœŸçš„ç¬‘å®¹ï¼Œæˆ‘æ„Ÿåˆ°æ— æ¯”çš„å¿«ä¹å’Œæ»¡è¶³"
            ],
            'expected_dominants': ['å¿«ä¹', 'å…´å¥‹', 'é’¦ä½©']
        },
        {
            'category': 'å¼ºçƒˆè´Ÿé¢æƒ…æ„Ÿ', 
            'texts': [
                "æˆ‘å¯¹è¿™ç§ä¸å…¬æ­£çš„å¾…é‡æ„Ÿåˆ°æžå…¶æ„¤æ€’ï¼",
                "å¬åˆ°è¿™ä¸ªåæ¶ˆæ¯ï¼Œæˆ‘å¿ƒå¦‚åˆ€å‰²ï¼Œæ‚²ä¼¤æ¬²ç»",
                "é¢å¯¹æ˜Žå¤©çš„è€ƒè¯•ï¼Œæˆ‘æ„Ÿåˆ°å‰æ‰€æœªæœ‰çš„ç„¦è™‘å’Œææƒ§"
            ],
            'expected_dominants': ['æ„¤æ€’', 'æ‚²ä¼¤', 'ç„¦è™‘']
        },
        {
            'category': 'å¤æ‚æ··åˆæƒ…æ„Ÿ',
            'texts': [
                "æ¯•ä¸šå…¸ç¤¼è®©æˆ‘æ—¢é«˜å…´åˆä¸èˆï¼Œå›žå¿†èµ·å¤§å­¦æ—¶å…‰",
                "çœ‹åˆ°è€ç…§ç‰‡ï¼Œæˆ‘æ—¢æ€€å¿µè¿‡åŽ»åˆå¯¹æœªæ¥å……æ»¡æœŸå¾…",
                "è¿™éƒ¨ç”µå½±è®©æˆ‘åˆå“­åˆç¬‘ï¼Œæƒ…æ„Ÿäº”å‘³æ‚é™ˆ"
            ],
            'expected_dominants': ['æ€€æ—§', 'æ¸´æœ›', 'å¨±ä¹']
        },
        {
            'category': 'å¤šè¯­è¨€æµ‹è¯•',
            'texts': [
                "I am absolutely fascinated by this discovery!",
                "Je me sens trÃ¨s romantique ce soir",
                "Estoy muy orgulloso de mis logros"
            ],
            'expected_dominants': ['å…¥è¿·', 'æµªæ¼«', 'é’¦ä½©']
        }
    ]
    
    all_vectors = []
    
    for category in test_cases:
        print(f"\nðŸ“Š {category['category']}:")
        category_vectors = []
        
        for i, text in enumerate(category['texts']):
            # èŽ·å–æƒ…æ„Ÿå‘é‡
            emotion_vector = analyze_text_emotion(text)
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_intensity = np.sum(emotion_vector)
            max_intensity = np.max(emotion_vector)
            active_count = np.sum(emotion_vector > 0.1)
            
            # æ‰¾å‡ºä¸»å¯¼æƒ…æ„Ÿ
            from emotion_mapper import GoEmotionsMapper
            from config import COWEN_KELTNER_EMOTIONS
            
            mapper = GoEmotionsMapper()
            if max_intensity > 0:
                top_emotions = mapper.get_top_emotions_from_vector(emotion_vector, 3)
                dominant_emotion = top_emotions[0][0] if top_emotions else "æ— "
            else:
                dominant_emotion = "æ— "
            
            print(f"   æ–‡æœ¬ {i+1}: {text[:40]}...")
            print(f"      ä¸»å¯¼æƒ…æ„Ÿ: {dominant_emotion} ({max_intensity:.3f})")
            print(f"      æ€»å¼ºåº¦: {total_intensity:.3f}, æ´»è·ƒæƒ…ç»ªæ•°: {active_count}")
            
            category_vectors.append(emotion_vector)
            all_vectors.append(emotion_vector)
        
        # è®¡ç®—ç±»åˆ«å†…çš„å¤šæ ·æ€§
        category_matrix = np.array(category_vectors)
        category_std = np.std(category_matrix)
        print(f"   ç±»åˆ«å†…å¤šæ ·æ€§: {category_std:.4f}")
    
    # æ•´ä½“å¤šæ ·æ€§åˆ†æž
    all_matrix = np.array(all_vectors)
    overall_std = np.std(all_matrix)
    overall_mean = np.mean(all_matrix)
    
    print(f"\nðŸ“ˆ æ•´ä½“ç»Ÿè®¡:")
    print(f"   æ€»ä½“å¤šæ ·æ€§ (æ ‡å‡†å·®): {overall_std:.4f}")
    print(f"   æ€»ä½“å‡å€¼: {overall_mean:.4f}")
    print(f"   é›¶å‘é‡æ¯”ä¾‹: {np.mean(np.sum(all_matrix, axis=1) == 0):.2%}")
    
    # åˆ¤æ–­ä¿®å¤æˆåŠŸ
    if overall_std > 0.05 and np.mean(np.sum(all_matrix, axis=1) == 0) < 0.5:
        print("âœ… æƒ…æ„Ÿå¤šæ ·æ€§æµ‹è¯•é€šè¿‡ - æ¨¡å—èƒ½å¤ŸåŒºåˆ†ä¸åŒæƒ…æ„Ÿ")
        return True
    else:
        print("âŒ æƒ…æ„Ÿå¤šæ ·æ€§æµ‹è¯•å¤±è´¥ - è¾“å‡ºè¿‡äºŽå•è°ƒæˆ–é›¶å‘é‡è¿‡å¤š")
        return False

def test_kg_integration_interface():
    """æµ‹è¯•ä¸ŽKGæ¨¡å—çš„é›†æˆæŽ¥å£"""
    print("\nðŸŒ‰ æµ‹è¯•KGæ¨¡å—é›†æˆæŽ¥å£")
    print("-" * 50)
    
    try:
        from inference_api import get_emotion_api, analyze_text_emotion
        
        # æµ‹è¯•å…¨å±€APIå®žä¾‹
        api = get_emotion_api()
        status = api.get_api_status()
        
        print(f"APIçŠ¶æ€: æ¨¡åž‹åŠ è½½={status['model_loaded']}, è®¾å¤‡={status['device']}")
        
        # æµ‹è¯•æ ¸å¿ƒKGæŽ¥å£å‡½æ•°
        test_inputs = [
            "ç”¨æˆ·çœ‹èµ·æ¥å¾ˆæ²®ä¸§ï¼Œéœ€è¦å®‰æ…°",
            "å®¢æˆ·å¯¹äº§å“éžå¸¸æ»¡æ„ï¼Œè¡¨ç¤ºå¾ˆå¼€å¿ƒ",
            "å¯¹è¯è€…è¡¨çŽ°å‡ºå¼ºçƒˆçš„æ„¤æ€’æƒ…ç»ª",
            "ç”¨æˆ·ä¼¼ä¹Žå¯¹è¯é¢˜å¾ˆæ„Ÿå…´è¶£å’Œå¥½å¥‡"
        ]
        
        print("\nðŸ§ª æµ‹è¯•KGé›†æˆæ ¸å¿ƒæŽ¥å£:")
        
        for i, text in enumerate(test_inputs, 1):
            # ä½¿ç”¨KGæ¨¡å—ä¼šè°ƒç”¨çš„æŽ¥å£
            emotion_vector = api.get_emotion_for_kg_module(text)
            
            # éªŒè¯è¾“å‡ºæ ¼å¼
            is_valid = (
                isinstance(emotion_vector, np.ndarray) and
                emotion_vector.shape == (27,) and
                np.all(emotion_vector >= 0) and 
                np.all(emotion_vector <= 1)
            )
            
            print(f"   æµ‹è¯• {i}: {text[:30]}...")
            print(f"      å‘é‡æ ¼å¼: {'âœ… æœ‰æ•ˆ' if is_valid else 'âŒ æ— æ•ˆ'}")
            print(f"      å‘é‡èŒƒå›´: [{emotion_vector.min():.3f}, {emotion_vector.max():.3f}]")
            
            if not is_valid:
                print(f"      âŒ KGæŽ¥å£æ ¼å¼éªŒè¯å¤±è´¥")
                return False
        
        # æµ‹è¯•å¿«æ·å‡½æ•°
        print(f"\nðŸ”§ æµ‹è¯•å¿«æ·å‡½æ•°:")
        quick_result = analyze_text_emotion("æµ‹è¯•å¿«æ·å‡½æ•°è°ƒç”¨")
        
        if isinstance(quick_result, np.ndarray) and quick_result.shape == (27,):
            print("   âœ… å¿«æ·å‡½æ•°æ­£å¸¸")
        else:
            print("   âŒ å¿«æ·å‡½æ•°å¼‚å¸¸")
            return False
        
        print("âœ… KGé›†æˆæŽ¥å£æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ KGé›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_performance_stability():
    """æµ‹è¯•æ€§èƒ½å’Œç¨³å®šæ€§"""
    print("\nâš¡ æµ‹è¯•æ€§èƒ½å’Œç¨³å®šæ€§")
    print("-" * 50)
    
    try:
        from inference_api import analyze_text_emotion
        import time
        
        # æ€§èƒ½æµ‹è¯•
        test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼ŒåŒ…å«ä¸€äº›æƒ…æ„Ÿå†…å®¹"
        
        # é¢„çƒ­
        analyze_text_emotion(test_text)
        
        # è®¡æ—¶æµ‹è¯•
        start_time = time.time()
        for _ in range(10):
            result = analyze_text_emotion(test_text)
        end_time = time.time()
        
        avg_time = (end_time - start_time) / 10
        print(f"å¹³å‡æŽ¨ç†æ—¶é—´: {avg_time:.3f} ç§’")
        
        if avg_time < 5.0:  # 5ç§’å†…å¯æŽ¥å—
            print("âœ… æ€§èƒ½æµ‹è¯•é€šè¿‡")
        else:
            print("âš ï¸  æ€§èƒ½è¾ƒæ…¢ä½†å¯ç”¨")
        
        # ç¨³å®šæ€§æµ‹è¯• - è¿žç»­ç›¸åŒè¾“å…¥åº”äº§ç”Ÿç›¸åŒè¾“å‡º
        results = []
        for _ in range(5):
            result = analyze_text_emotion("ç¨³å®šæ€§æµ‹è¯•æ–‡æœ¬")
            results.append(result)
        
        # æ£€æŸ¥ä¸€è‡´æ€§
        consistent = all(np.allclose(results[0], result) for result in results[1:])
        
        if consistent:
            print("âœ… ç¨³å®šæ€§æµ‹è¯•é€šè¿‡ - ç›¸åŒè¾“å…¥äº§ç”Ÿä¸€è‡´è¾“å‡º")
        else:
            print("âŒ ç¨³å®šæ€§æµ‹è¯•å¤±è´¥ - è¾“å‡ºä¸ä¸€è‡´")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½ç¨³å®šæ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """è¿è¡Œå®Œæ•´çš„æœ€ç»ˆé›†æˆæµ‹è¯•"""
    print("ðŸš€ ACæƒ…æ„Ÿåˆ†æžæ¨¡å—æœ€ç»ˆé›†æˆæµ‹è¯•")
    print("=" * 60)
    print("éªŒè¯ä¿®å¤åŽçš„ACæ¨¡å—åŠŸèƒ½å®Œæ•´æ€§å’ŒKGé›†æˆèƒ½åŠ›")
    print("")
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_results = []
    
    # æµ‹è¯•1: æƒ…æ„Ÿå¤šæ ·æ€§
    test_results.append(test_emotion_diversity())
    
    # æµ‹è¯•2: KGé›†æˆæŽ¥å£
    test_results.append(test_kg_integration_interface())
    
    # æµ‹è¯•3: æ€§èƒ½ç¨³å®šæ€§
    test_results.append(test_performance_stability())
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ðŸ“‹ æœ€ç»ˆé›†æˆæµ‹è¯•ç»“æžœ:")
    
    test_names = ["æƒ…æ„Ÿå¤šæ ·æ€§è¯†åˆ«", "KGæ¨¡å—é›†æˆæŽ¥å£", "æ€§èƒ½ç¨³å®šæ€§"]
    
    for i, (name, result) in enumerate(zip(test_names, test_results)):
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {i+1}. {name}: {status}")
    
    success_rate = sum(test_results) / len(test_results)
    
    print(f"\nðŸŽ¯ æ€»ä½“æˆåŠŸçŽ‡: {success_rate:.1%}")
    
    if success_rate >= 1.0:
        print("\nðŸŽ‰ æ­å–œï¼ACæƒ…æ„Ÿåˆ†æžæ¨¡å—ä¿®å¤å®Œå…¨æˆåŠŸï¼")
        print("   âœ… åŠŸèƒ½å®Œå…¨æ¢å¤ï¼Œæƒ…æ„Ÿè¯†åˆ«å‡†ç¡®")  
        print("   âœ… ä¸ŽKGæ¨¡å—é›†æˆæŽ¥å£æ­£å¸¸")
        print("   âœ… æ€§èƒ½å’Œç¨³å®šæ€§ç¬¦åˆè¦æ±‚")
        print("\nðŸ’¡ æ¨¡å—çŽ°åœ¨å¯ä»¥æŠ•å…¥ä½¿ç”¨ï¼Œä¸ºKGæ¨¡å—æä¾›å‡†ç¡®çš„æƒ…æ„Ÿåˆ†æžæœåŠ¡")
        
    elif success_rate >= 0.67:
        print("\nâœ… ACæƒ…æ„Ÿåˆ†æžæ¨¡å—ä¿®å¤åŸºæœ¬æˆåŠŸï¼")
        print("   å¤§éƒ¨åˆ†åŠŸèƒ½æ­£å¸¸ï¼Œå¯ä»¥ä½¿ç”¨")
        print("   å»ºè®®ç›‘æŽ§è¿è¡ŒçŠ¶æ€ï¼Œå¿…è¦æ—¶è¿›ä¸€æ­¥ä¼˜åŒ–")
        
    else:
        print("\nâš ï¸  ACæƒ…æ„Ÿåˆ†æžæ¨¡å—ä¿®å¤ä¸å®Œå…¨")
        print("   éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•å’Œä¿®å¤")
    
    return success_rate >= 0.67

if __name__ == "__main__":
    main()