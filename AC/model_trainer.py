#!/usr/bin/env python3
"""
xlm-robertaæ¨¡å‹å¾®è°ƒè®­ç»ƒå™¨

åŸºäºGoEmotionsæ•°æ®é›†å¾®è°ƒxlm-robertaæ¨¡å‹
æ”¯æŒå¤šæ ‡ç­¾æƒ…æ„Ÿåˆ†ç±»å’ŒC&Kæƒ…ç»ªä½“ç³»è½¬æ¢
"""

import os
import torch
import numpy as np
import pandas as pd
import logging
from typing import Dict, List, Tuple, Optional
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, classification_report
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    AutoConfig,
    Trainer,
    TrainingArguments,
    EvalPrediction,
    DataCollatorWithPadding
)
from torch.utils.data import Dataset
import warnings
warnings.filterwarnings("ignore")

from config import (
    MODEL_CONFIG, 
    MODEL_PATHS, 
    DATA_PATHS,
    COWEN_KELTNER_EMOTIONS,
    GOEMOTIONS_TO_CK_MAPPING
)
from emotion_mapper import GoEmotionsMapper

logger = logging.getLogger(__name__)

class EmotionDataset(Dataset):
    """æƒ…æ„Ÿæ•°æ®é›†ç±»"""
    
    def __init__(self, texts: List[str], labels: np.ndarray, tokenizer, max_length: int = 512):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            labels: æ ‡ç­¾çŸ©é˜µ (N, 27)
            tokenizer: åˆ†è¯å™¨
            max_length: æœ€å¤§åºåˆ—é•¿åº¦
        """
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length
        
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = str(self.texts[idx])
        labels = self.labels[idx]
        
        # åˆ†è¯
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(labels, dtype=torch.float)
        }

class ModelTrainer:
    """xlm-robertaæ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, config: Dict = None):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            config: è®­ç»ƒé…ç½®å­—å…¸
        """
        self.config = config or MODEL_CONFIG
        self.mapper = GoEmotionsMapper()
        self.device = self._detect_device()
        
        logger.info("âœ… æ¨¡å‹è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   ä½¿ç”¨è®¾å¤‡: {self.device}")
        logger.info(f"   æ¨¡å‹é…ç½®: {self.config['model_name']}")
    
    def _detect_device(self) -> str:
        """æ£€æµ‹å¯ç”¨è®¾å¤‡"""
        if torch.cuda.is_available():
            return "cuda"
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            return "mps"  
        else:
            return "cpu"
    
    def prepare_data(self, data_path: str) -> Tuple[List[str], np.ndarray]:
        """
        å‡†å¤‡è®­ç»ƒæ•°æ®
        
        Args:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            
        Returns:
            (texts, labels): æ–‡æœ¬åˆ—è¡¨å’Œæ ‡ç­¾çŸ©é˜µ
        """
        try:
            logger.info(f"ğŸ“‚ å‡†å¤‡è®­ç»ƒæ•°æ®: {data_path}")
            
            # è¯»å–æ•°æ®
            if data_path.endswith('.csv'):
                df = pd.read_csv(data_path)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æ ¼å¼: {data_path}")
            
            logger.info(f"   åŸå§‹æ•°æ®: {len(df)} æ¡æ ·æœ¬")
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯C&Kæ ¼å¼
            if all(emotion in df.columns for emotion in COWEN_KELTNER_EMOTIONS):
                logger.info("   æ£€æµ‹åˆ°C&Kæ ¼å¼æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨")
                texts = df['text'].tolist()
                labels = df[COWEN_KELTNER_EMOTIONS].values.astype(np.float32)
            else:
                # GoEmotionsæ ¼å¼ï¼Œéœ€è¦è½¬æ¢
                logger.info("   æ£€æµ‹åˆ°GoEmotionsæ ¼å¼ï¼Œå¼€å§‹è½¬æ¢")
                texts = df['text'].tolist()
                
                # è½¬æ¢æ ‡ç­¾
                labels_list = []
                for idx, row in df.iterrows():
                    ge_scores = {label: row[label] for label in self.mapper.goemotions_labels if label in row}
                    ck_vector = self.mapper.map_goemotions_to_ck_vector(ge_scores)
                    labels_list.append(ck_vector)
                
                labels = np.array(labels_list, dtype=np.float32)
            
            # æ•°æ®éªŒè¯
            assert len(texts) == len(labels), "æ–‡æœ¬å’Œæ ‡ç­¾æ•°é‡ä¸åŒ¹é…"
            assert labels.shape[1] == 27, f"æ ‡ç­¾ç»´åº¦é”™è¯¯: æœŸæœ›27ç»´ï¼Œå®é™…{labels.shape[1]}ç»´"
            
            # ç»Ÿè®¡ä¿¡æ¯
            active_labels = np.sum(labels > 0, axis=1)
            logger.info(f"   å¤„ç†åæ•°æ®: {len(texts)} æ¡æ ·æœ¬")
            logger.info(f"   å¹³å‡æ´»è·ƒæƒ…ç»ªæ•°: {np.mean(active_labels):.2f}")
            logger.info(f"   æ ‡ç­¾åˆ†å¸ƒ: min={np.min(labels):.3f}, max={np.max(labels):.3f}")
            
            return texts, labels
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
            raise
    
    def create_datasets(self, texts: List[str], labels: np.ndarray, 
                       test_size: float = 0.2, val_size: float = 0.1) -> Tuple[EmotionDataset, EmotionDataset, EmotionDataset]:
        """
        åˆ›å»ºè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            labels: æ ‡ç­¾çŸ©é˜µ
            test_size: æµ‹è¯•é›†æ¯”ä¾‹
            val_size: éªŒè¯é›†æ¯”ä¾‹
            
        Returns:
            (train_dataset, val_dataset, test_dataset)
        """
        try:
            logger.info("ğŸ”„ åˆ›å»ºæ•°æ®é›†åˆ†å‰²")
            
            # åˆå§‹åŒ–tokenizer
            tokenizer = AutoTokenizer.from_pretrained(
                self.config["model_name"],
                cache_dir=MODEL_PATHS["pretrained_cache"]
            )
            
            # ç¬¬ä¸€æ¬¡åˆ†å‰²: è®­ç»ƒ+éªŒè¯ vs æµ‹è¯•
            X_temp, X_test, y_temp, y_test = train_test_split(
                texts, labels, test_size=test_size, random_state=42, stratify=None
            )
            
            # ç¬¬äºŒæ¬¡åˆ†å‰²: è®­ç»ƒ vs éªŒè¯
            val_size_adjusted = val_size / (1 - test_size)  # è°ƒæ•´éªŒè¯é›†æ¯”ä¾‹
            X_train, X_val, y_train, y_val = train_test_split(
                X_temp, y_temp, test_size=val_size_adjusted, random_state=42, stratify=None
            )
            
            # åˆ›å»ºæ•°æ®é›†å¯¹è±¡
            train_dataset = EmotionDataset(
                X_train, y_train, tokenizer, self.config["max_length"]
            )
            val_dataset = EmotionDataset(
                X_val, y_val, tokenizer, self.config["max_length"]
            )
            test_dataset = EmotionDataset(
                X_test, y_test, tokenizer, self.config["max_length"]
            )
            
            logger.info(f"âœ… æ•°æ®é›†åˆ›å»ºå®Œæˆ:")
            logger.info(f"   è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
            logger.info(f"   éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬") 
            logger.info(f"   æµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬")
            
            return train_dataset, val_dataset, test_dataset
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
            raise
    
    def compute_metrics(self, eval_pred: EvalPrediction) -> Dict[str, float]:
        """
        è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        
        Args:
            eval_pred: è¯„ä¼°é¢„æµ‹ç»“æœ
            
        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        predictions, labels = eval_pred
        
        # åº”ç”¨sigmoidæ¿€æ´»
        predictions = 1 / (1 + np.exp(-predictions))  # sigmoid
        
        # äºŒå€¼åŒ–é¢„æµ‹ (é˜ˆå€¼=0.5)
        binary_predictions = (predictions > 0.5).astype(int)
        binary_labels = (labels > 0.5).astype(int)
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = {}
        
        # Macro F1
        f1_macro = f1_score(binary_labels, binary_predictions, average='macro', zero_division=0)
        metrics['f1_macro'] = f1_macro
        
        # Micro F1  
        f1_micro = f1_score(binary_labels, binary_predictions, average='micro', zero_division=0)
        metrics['f1_micro'] = f1_micro
        
        # æ¯ä¸ªæƒ…ç»ªçš„F1åˆ†æ•°
        f1_per_emotion = f1_score(binary_labels, binary_predictions, average=None, zero_division=0)
        for i, emotion in enumerate(COWEN_KELTNER_EMOTIONS):
            metrics[f'f1_{emotion}'] = f1_per_emotion[i]
        
        # å‡†ç¡®ç‡ (Hamming accuracy)
        hamming_acc = accuracy_score(binary_labels, binary_predictions)
        metrics['hamming_accuracy'] = hamming_acc
        
        # å®Œå…¨åŒ¹é…å‡†ç¡®ç‡
        exact_match = np.all(binary_labels == binary_predictions, axis=1).mean()
        metrics['exact_match_accuracy'] = exact_match
        
        return metrics
    
    def train_model(self, train_dataset: EmotionDataset, val_dataset: EmotionDataset,
                   output_dir: str = None) -> None:
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            train_dataset: è®­ç»ƒæ•°æ®é›†
            val_dataset: éªŒè¯æ•°æ®é›†  
            output_dir: è¾“å‡ºç›®å½•
        """
        try:
            output_dir = output_dir or str(MODEL_PATHS["finetuned_model"])
            logger.info(f"ğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ")
            logger.info(f"   è¾“å‡ºç›®å½•: {output_dir}")
            
            # åˆå§‹åŒ–æ¨¡å‹é…ç½®
            config = AutoConfig.from_pretrained(
                self.config["model_name"],
                num_labels=27,
                problem_type="multi_label_classification",
                cache_dir=MODEL_PATHS["pretrained_cache"]
            )
            
            # åˆå§‹åŒ–æ¨¡å‹
            model = AutoModelForSequenceClassification.from_pretrained(
                self.config["model_name"],
                config=config,
                cache_dir=MODEL_PATHS["pretrained_cache"]
            )
            
            # åˆå§‹åŒ–tokenizer
            tokenizer = AutoTokenizer.from_pretrained(
                self.config["model_name"], 
                cache_dir=MODEL_PATHS["pretrained_cache"]
            )
            
            # æ•°æ®æ•´ç†å™¨
            data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
            
            # è®­ç»ƒå‚æ•°
            training_args = TrainingArguments(
                output_dir=output_dir,
                num_train_epochs=self.config["num_epochs"],
                per_device_train_batch_size=self.config["batch_size"],
                per_device_eval_batch_size=self.config["batch_size"],
                gradient_accumulation_steps=self.config["gradient_accumulation_steps"],
                warmup_steps=self.config["warmup_steps"],
                weight_decay=self.config["weight_decay"],
                learning_rate=self.config["learning_rate"],
                logging_steps=100,
                eval_steps=500,
                save_steps=500,
                evaluation_strategy="steps",
                save_strategy="steps",
                load_best_model_at_end=True,
                metric_for_best_model="f1_macro",
                greater_is_better=True,
                report_to=None,  # ç¦ç”¨wandbç­‰æ—¥å¿—
                push_to_hub=False,
                dataloader_num_workers=0,  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
            )
            
            # åˆå§‹åŒ–Trainer
            trainer = Trainer(
                model=model,
                args=training_args,
                train_dataset=train_dataset,
                eval_dataset=val_dataset,
                tokenizer=tokenizer,
                data_collator=data_collator,
                compute_metrics=self.compute_metrics,
            )
            
            # å¼€å§‹è®­ç»ƒ
            logger.info("ğŸ”„ å¼€å§‹è®­ç»ƒ...")
            train_result = trainer.train()
            
            # ä¿å­˜æ¨¡å‹
            logger.info("ğŸ’¾ ä¿å­˜è®­ç»ƒåçš„æ¨¡å‹...")
            trainer.save_model()
            tokenizer.save_pretrained(output_dir)
            
            # è®­ç»ƒæ€»ç»“
            logger.info("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")
            logger.info(f"   è®­ç»ƒæŸå¤±: {train_result.training_loss:.4f}")
            logger.info(f"   è®­ç»ƒæ­¥æ•°: {train_result.global_step}")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            raise
    
    def evaluate_model(self, test_dataset: EmotionDataset, model_path: str = None) -> Dict[str, float]:
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½
        
        Args:
            test_dataset: æµ‹è¯•æ•°æ®é›†
            model_path: æ¨¡å‹è·¯å¾„
            
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        try:
            model_path = model_path or str(MODEL_PATHS["finetuned_model"])
            logger.info(f"ğŸ“Š å¼€å§‹æ¨¡å‹è¯„ä¼°: {model_path}")
            
            # åŠ è½½æ¨¡å‹å’Œtokenizer
            model = AutoModelForSequenceClassification.from_pretrained(model_path)
            tokenizer = AutoTokenizer.from_pretrained(model_path)
            
            # æ•°æ®æ•´ç†å™¨
            data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
            
            # è¯„ä¼°å‚æ•°
            eval_args = TrainingArguments(
                output_dir="./temp_eval",
                per_device_eval_batch_size=self.config["batch_size"],
                dataloader_num_workers=0,
                report_to=None
            )
            
            # Trainer
            trainer = Trainer(
                model=model,
                args=eval_args,
                eval_dataset=test_dataset,
                tokenizer=tokenizer,
                data_collator=data_collator,
                compute_metrics=self.compute_metrics,
            )
            
            # è¯„ä¼°
            eval_results = trainer.evaluate()
            
            logger.info("âœ… æ¨¡å‹è¯„ä¼°å®Œæˆ!")
            logger.info(f"   F1 Macro: {eval_results['eval_f1_macro']:.4f}")
            logger.info(f"   F1 Micro: {eval_results['eval_f1_micro']:.4f}")
            logger.info(f"   Hamming Accuracy: {eval_results['eval_hamming_accuracy']:.4f}")
            logger.info(f"   Exact Match: {eval_results['eval_exact_match_accuracy']:.4f}")
            
            return eval_results
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
            return {}

def main():
    """è®­ç»ƒè„šæœ¬ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹xlm-robertaæƒ…æ„Ÿåˆ†ç±»æ¨¡å‹è®­ç»ƒ")
    print("=" * 60)
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨
    trainer = ModelTrainer()
    
    # æ£€æŸ¥æ•°æ®è·¯å¾„
    train_data_path = DATA_PATHS["goemotions_train"]
    if not train_data_path.exists():
        logger.error(f"âŒ è®­ç»ƒæ•°æ®ä¸å­˜åœ¨: {train_data_path}")
        logger.info("ğŸ’¡ è¯·å…ˆä¸‹è½½å¹¶å‡†å¤‡GoEmotionsæ•°æ®é›†")
        return
    
    try:
        # å‡†å¤‡æ•°æ®
        texts, labels = trainer.prepare_data(str(train_data_path))
        
        # åˆ›å»ºæ•°æ®é›†
        train_dataset, val_dataset, test_dataset = trainer.create_datasets(texts, labels)
        
        # è®­ç»ƒæ¨¡å‹  
        trainer.train_model(train_dataset, val_dataset)
        
        # è¯„ä¼°æ¨¡å‹
        eval_results = trainer.evaluate_model(test_dataset)
        
        print(f"\nğŸ‰ è®­ç»ƒæµç¨‹å®Œæˆ!")
        print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {MODEL_PATHS['finetuned_model']}")
        
    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒæµç¨‹å¤±è´¥: {e}")
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")

if __name__ == "__main__":
    main()