#!/usr/bin/env python3
"""
æƒ…æ„Ÿè®¡ç®—æ¨¡å—æ¨ç†API

æä¾›ç»Ÿä¸€çš„æƒ…æ„Ÿåˆ†ææ¥å£ï¼Œä¸KGæ¨¡å—å®Œç¾é›†æˆ
æ”¯æŒå•æ–‡æœ¬ã€æ‰¹é‡æ–‡æœ¬çš„æƒ…æ„Ÿè¯†åˆ«å’Œ27ç»´å‘é‡è¾“å‡º
"""

import sys
import os
import numpy as np
import logging
import pandas as pd
from typing import Dict, List, Union, Optional, Any
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

try:
    from .emotion_classifier import CompatibleEmotionClassifier as EmotionClassifier
    from .emotion_mapper import GoEmotionsMapper
except ImportError:
    from emotion_classifier import CompatibleEmotionClassifier as EmotionClassifier
    from emotion_mapper import GoEmotionsMapper
try:
    from .config import COWEN_KELTNER_EMOTIONS, INFERENCE_CONFIG, MODEL_PATHS
except ImportError:
    from config import COWEN_KELTNER_EMOTIONS, INFERENCE_CONFIG, MODEL_PATHS

logger = logging.getLogger(__name__)

class EmotionInferenceAPI:
    """æƒ…æ„Ÿåˆ†ææ¨ç†API"""
    
    def __init__(self, model_path: str = None, load_finetuned: bool = True):
        """
        åˆå§‹åŒ–æ¨ç†API
        
        Args:
            model_path: è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„
            load_finetuned: æ˜¯å¦åŠ è½½å¾®è°ƒæ¨¡å‹
        """
        self.emotion_names = COWEN_KELTNER_EMOTIONS
        self.model_path = model_path
        
        # åˆå§‹åŒ–åˆ†ç±»å™¨
        self.classifier = EmotionClassifier(load_pretrained=not load_finetuned)
        
        # å°è¯•åŠ è½½å¾®è°ƒæ¨¡å‹
        if load_finetuned:
            try:
                finetuned_path = model_path or MODEL_PATHS["finetuned_model"]
                if Path(finetuned_path).exists():
                    self.classifier.load_finetuned_model(str(finetuned_path))
                    logger.info("âœ… ä½¿ç”¨å¾®è°ƒæ¨¡å‹")
                else:
                    logger.warning("âš ï¸  å¾®è°ƒæ¨¡å‹ä¸å­˜åœ¨ï¼Œä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹")
            except Exception as e:
                logger.warning(f"âš ï¸  å¾®è°ƒæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹: {e}")
        
        # åˆå§‹åŒ–æ˜ å°„å™¨
        self.mapper = GoEmotionsMapper()
        
        logger.info("âœ… æƒ…æ„Ÿæ¨ç†APIåˆå§‹åŒ–å®Œæˆ")
    
    def analyze_single_text(self, text: str, output_format: str = "vector", top_k: int = 7) -> Union[np.ndarray, Dict[str, float], List[tuple]]:
        """
        åˆ†æå•ä¸ªæ–‡æœ¬çš„æƒ…æ„Ÿ
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            output_format: è¾“å‡ºæ ¼å¼ ("vector", "dict", "top_k")
            top_k: å½“ output_format ä¸º "top_k" æ—¶ï¼ŒæŒ‡å®šè¿”å›å‰kä¸ªæƒ…ç»ªçš„æ•°é‡
            
        Returns:
            æ ¹æ®formatè¿”å›ä¸åŒæ ¼å¼çš„ç»“æœ
        """
        try:
            # åŸºç¡€éªŒè¯
            if not text or len(text.strip()) < 1:
                logger.warning("âš ï¸  è¾“å…¥æ–‡æœ¬ä¸ºç©º")
                if output_format == "vector":
                    return np.zeros(27, dtype=np.float32)
                elif output_format == "dict":
                    return {emotion: 0.0 for emotion in self.emotion_names}
                else:  # top_k
                    return []
            
            # è·å–æƒ…æ„Ÿå‘é‡
            emotion_vector = self.classifier.predict_single(text)
            
            # æ ¹æ®è¾“å‡ºæ ¼å¼è¿”å›ç»“æœ
            if output_format == "vector":
                return emotion_vector
            elif output_format == "dict":
                return self.mapper.map_ck_vector_to_dict(emotion_vector)
            elif output_format == "top_k":
                # â˜…â˜…â˜… æ ¸å¿ƒä¿®æ”¹ï¼šä½¿ç”¨ä¼ å…¥çš„ top_k å‚æ•°ï¼Œè€Œä¸æ˜¯å†™æ­»çš„ 5 â˜…â˜…â˜…
                return self.mapper.get_top_emotions_from_vector(emotion_vector, top_k)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„è¾“å‡ºæ ¼å¼: {output_format}")
                
        except Exception as e:
            logger.error(f"âŒ å•æ–‡æœ¬æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤ç»“æœ
            if output_format == "vector":
                return np.zeros(27, dtype=np.float32)
            elif output_format == "dict":
                return {emotion: 0.0 for emotion in self.emotion_names}
            else:
                return []
    
    def analyze_batch_texts(self, texts: List[str], batch_size: int = None) -> np.ndarray:
        """
        æ‰¹é‡åˆ†ææ–‡æœ¬æƒ…æ„Ÿ
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
            
        Returns:
            (N, 27) æƒ…æ„Ÿå‘é‡çŸ©é˜µ
        """
        try:
            if not texts:
                return np.zeros((0, 27), dtype=np.float32)
            
            batch_size = batch_size or INFERENCE_CONFIG["max_batch_size"]
            return self.classifier.predict_batch(texts, batch_size)
            
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            return np.zeros((len(texts), 27), dtype=np.float32)
    
    def get_emotion_for_kg_module(self, text: str) -> np.ndarray:
        """
        ä¸ºKGæ¨¡å—æä¾›æ ‡å‡†åŒ–çš„27ç»´æƒ…æ„Ÿå‘é‡
        
        è¿™æ˜¯ä¸KGæ¨¡å—é›†æˆçš„æ ¸å¿ƒæ¥å£
        
        Args:
            text: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            
        Returns:
            np.ndarray: æ ‡å‡†åŒ–çš„27ç»´C&Kæƒ…æ„Ÿå‘é‡ [0, 1]
        """
        try:
            logger.info(f"ğŸ§  ä¸ºKGæ¨¡å—åˆ†ææƒ…æ„Ÿ: {text[:50]}...")
            
            # è·å–æƒ…æ„Ÿå‘é‡
            emotion_vector = self.analyze_single_text(text, output_format="vector")
            
            # éªŒè¯å‘é‡æ ¼å¼
            if not self.mapper.validate_vector(emotion_vector):
                logger.error("âŒ æƒ…æ„Ÿå‘é‡æ ¼å¼éªŒè¯å¤±è´¥")
                return np.zeros(27, dtype=np.float32)
            
            # è®°å½•ä¸»è¦æƒ…æ„Ÿ
            top_emotions = self.mapper.get_top_emotions_from_vector(emotion_vector, 3)
            logger.info(f"   ä¸»è¦æƒ…æ„Ÿ: {[(name, f'{score:.3f}') for name, score in top_emotions]}")
            
            return emotion_vector
            
        except Exception as e:
            logger.error(f"âŒ KGæ¨¡å—æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            return np.zeros(27, dtype=np.float32)
    
    def analyze_emotion_with_context(self, text: str) -> Dict[str, Any]:
        """
        å¸¦ä¸Šä¸‹æ–‡çš„æƒ…æ„Ÿåˆ†æ
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            åŒ…å«è¯¦ç»†åˆ†æä¿¡æ¯çš„å­—å…¸
        """
        try:
            # åŸºç¡€æƒ…æ„Ÿåˆ†æ
            emotion_vector = self.analyze_single_text(text, output_format="vector")
            emotion_dict = self.mapper.map_ck_vector_to_dict(emotion_vector)
            top_emotions = self.mapper.get_top_emotions_from_vector(emotion_vector, 5)
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            total_intensity = float(np.sum(emotion_vector))
            max_intensity = float(np.max(emotion_vector))
            active_emotions = len([score for score in emotion_vector if score > 0.1])
            
            # æƒ…æ„Ÿåˆ†ç±»
            positive_emotions = ["å¿«ä¹", "å…´å¥‹", "å¨±ä¹", "é’¦ä½©", "å´‡æ‹œ", "å®¡ç¾æ¬£èµ", "æ•¬ç•", "å…¥è¿·", "å…´è¶£", "æµªæ¼«"]
            negative_emotions = ["æ„¤æ€’", "ç„¦è™‘", "æ‚²ä¼¤", "ææƒ§", "å†…ç–š", "ææ€–", "å¤±æœ›", "åŒæ¶", "å«‰å¦’", "è”‘è§†"]
            neutral_emotions = ["å¹³é™", "æ— èŠ", "å›°æƒ‘", "å°´å°¬", "åŒæƒ…", "æ¸´æœ›", "æ€€æ—§"]
            
            positive_score = sum(emotion_dict[e] for e in positive_emotions if e in emotion_dict)
            negative_score = sum(emotion_dict[e] for e in negative_emotions if e in emotion_dict)
            neutral_score = sum(emotion_dict[e] for e in neutral_emotions if e in emotion_dict)
            
            return {
                "input_text": text,
                "emotion_vector": emotion_vector.tolist(),
                "emotion_dict": emotion_dict,
                "top_emotions": top_emotions,
                "statistics": {
                    "total_intensity": total_intensity,
                    "max_intensity": max_intensity,
                    "active_emotions_count": active_emotions,
                    "emotion_balance": {
                        "positive": positive_score,
                        "negative": negative_score,
                        "neutral": neutral_score
                    }
                },
                "primary_emotion": top_emotions[0] if top_emotions else ("å¹³é™", 0.0),
                "analysis_timestamp": pd.Timestamp.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ ä¸Šä¸‹æ–‡æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            return {
                "input_text": text,
                "emotion_vector": np.zeros(27).tolist(),
                "error": str(e)
            }
    
    def test_kg_integration(self, test_texts: List[str] = None) -> Dict[str, Any]:
        """
        æµ‹è¯•ä¸KGæ¨¡å—çš„é›†æˆ
        
        Args:
            test_texts: æµ‹è¯•æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            æµ‹è¯•ç»“æœ
        """
        default_texts = [
            "æˆ‘ä»Šå¤©æ„Ÿåˆ°éå¸¸ç„¦è™‘ï¼Œéš¾ä»¥å…¥ç¡",
            "è¿™é¦–éŸ³ä¹è®©æˆ‘æ„Ÿåˆ°å¹³é™å’Œæ”¾æ¾",
            "æˆ‘å¯¹è¿™ä¸ªç»“æœæ„Ÿåˆ°éå¸¸å¼€å¿ƒå’Œå…´å¥‹",
            "I feel sad and disappointed about the news",
            "Cette musique me rend nostalgique"
        ]
        
        test_texts = test_texts or default_texts
        results = []
        
        logger.info("ğŸ§ª å¼€å§‹KGé›†æˆæµ‹è¯•")
        
        for text in test_texts:
            try:
                # ä½¿ç”¨KGæ¥å£
                emotion_vector = self.get_emotion_for_kg_module(text)
                
                # åˆ†æç»“æœ
                top_emotions = self.mapper.get_top_emotions_from_vector(emotion_vector, 3)
                
                result = {
                    "text": text,
                    "emotion_vector_shape": emotion_vector.shape,
                    "vector_sum": float(np.sum(emotion_vector)),
                    "top_emotions": top_emotions,
                    "vector_valid": self.mapper.validate_vector(emotion_vector)
                }
                
                results.append(result)
                
            except Exception as e:
                logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {text[:30]}... -> {e}")
                results.append({
                    "text": text,
                    "error": str(e)
                })
        
        # ç»Ÿè®¡
        successful_tests = len([r for r in results if "error" not in r])
        
        summary = {
            "total_tests": len(test_texts),
            "successful_tests": successful_tests,
            "success_rate": successful_tests / len(test_texts),
            "test_results": results
        }
        
        logger.info(f"âœ… KGé›†æˆæµ‹è¯•å®Œæˆ: {successful_tests}/{len(test_texts)} æˆåŠŸ")
        
        return summary
    
    def get_api_status(self) -> Dict[str, Any]:
        """è·å–APIçŠ¶æ€ä¿¡æ¯"""
        return {
            "api_version": "1.0.0",
            "model_loaded": self.classifier is not None,
            "model_path": str(self.model_path) if self.model_path else "default",
            "supported_emotions": len(self.emotion_names),
            "emotion_names": self.emotion_names,
            "inference_config": INFERENCE_CONFIG,
            "device": getattr(self.classifier, 'device', 'unknown') if self.classifier else 'unknown'
        }

# å…¨å±€APIå®ä¾‹ (å•ä¾‹æ¨¡å¼)
_global_api_instance = None

def get_emotion_api(model_path: str = None, load_finetuned: bool = True) -> EmotionInferenceAPI:
    """
    è·å–å…¨å±€æƒ…æ„ŸAPIå®ä¾‹
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„
        load_finetuned: æ˜¯å¦åŠ è½½å¾®è°ƒæ¨¡å‹
        
    Returns:
        EmotionInferenceAPIå®ä¾‹
    """
    global _global_api_instance
    
    if _global_api_instance is None:
        _global_api_instance = EmotionInferenceAPI(model_path, load_finetuned)
    
    return _global_api_instance

def analyze_text_emotion(text: str) -> np.ndarray:
    """
    å¿«æ·å‡½æ•°ï¼šåˆ†ææ–‡æœ¬æƒ…æ„Ÿå¹¶è¿”å›27ç»´å‘é‡
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        
    Returns:
        27ç»´æƒ…æ„Ÿå‘é‡
    """
    api = get_emotion_api()
    return api.get_emotion_for_kg_module(text)

def main():
    """æµ‹è¯•æ¨ç†API"""
    print("ğŸ”® æƒ…æ„Ÿæ¨ç†APIæµ‹è¯•")
    print("=" * 50)
    
    # åˆå§‹åŒ–API
    api = EmotionInferenceAPI(load_finetuned=False)  # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æµ‹è¯•
    
    # æ˜¾ç¤ºçŠ¶æ€
    status = api.get_api_status()
    print(f"\nğŸ“Š APIçŠ¶æ€:")
    print(f"   æ¨¡å‹å·²åŠ è½½: {status['model_loaded']}")
    print(f"   æ”¯æŒæƒ…ç»ªæ•°: {status['supported_emotions']}")
    print(f"   ä½¿ç”¨è®¾å¤‡: {status['device']}")
    
    # æµ‹è¯•å•æ–‡æœ¬åˆ†æ
    print(f"\nğŸ§ª å•æ–‡æœ¬æƒ…æ„Ÿåˆ†ææµ‹è¯•:")
    test_text = "æˆ‘ä»Šå¤©æ„Ÿåˆ°éå¸¸å¼€å¿ƒå’Œå…´å¥‹ï¼Œè¿™é¦–éŸ³ä¹è®©æˆ‘æƒ³èµ·äº†ç¾å¥½çš„å›å¿†"
    
    # ä¸åŒè¾“å‡ºæ ¼å¼
    vector_result = api.analyze_single_text(test_text, "vector")
    dict_result = api.analyze_single_text(test_text, "dict")
    topk_result = api.analyze_single_text(test_text, "top_k")
    
    print(f"æ–‡æœ¬: {test_text}")
    print(f"å‘é‡å½¢çŠ¶: {vector_result.shape}")
    print(f"å‘é‡å¼ºåº¦: {np.sum(vector_result):.3f}")
    print(f"ä¸»è¦æƒ…ç»ª: {topk_result[:3]}")
    
    # æµ‹è¯•ä¸Šä¸‹æ–‡åˆ†æ
    print(f"\nğŸ“ˆ ä¸Šä¸‹æ–‡æƒ…æ„Ÿåˆ†æ:")
    context_result = api.analyze_emotion_with_context(test_text)
    print(f"æ€»å¼ºåº¦: {context_result['statistics']['total_intensity']:.3f}")
    print(f"æ´»è·ƒæƒ…ç»ªæ•°: {context_result['statistics']['active_emotions_count']}")
    print(f"æƒ…ç»ªå¹³è¡¡: {context_result['statistics']['emotion_balance']}")
    
    # æµ‹è¯•KGé›†æˆ
    print(f"\nğŸŒ‰ KGæ¨¡å—é›†æˆæµ‹è¯•:")
    kg_test = api.test_kg_integration()
    print(f"æµ‹è¯•æˆåŠŸç‡: {kg_test['success_rate']:.2%}")
    
    print(f"\nâœ… æ¨ç†APIæµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    import pandas as pd  # å¯¼å…¥pandasç”¨äºæ—¶é—´æˆ³
    main()